{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e374718",
   "metadata": {},
   "source": [
    "# KVP10k Key-Value Relation Extraction\n",
    "\n",
    "Denne Colab-notebooken viser hvordan du kan kjøre LayoutLMv3-basert nøkkel-verdi-relasjons­ekstraksjon på KVP10k-datasettet, og visualisere resultatet med piler mellom `KEY`- og `VALUE`-spans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer nødvendige pakker\n",
    "!pip install transformers torch pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cbe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koble til Google Drive (for å lese data fra Drive)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3Model\n",
    "\n",
    "# Hjelpefunksjoner\n",
    "def normalize_bbox(bbox, width, height):\n",
    "    left, top, right, bottom = bbox\n",
    "    return [\n",
    "        int(1000 * left / width),\n",
    "        int(1000 * top / height),\n",
    "        int(1000 * right / width),\n",
    "        int(1000 * bottom / height),\n",
    "    ]\n",
    "\n",
    "def unnormalize_box(box, width, height):\n",
    "    left = int(box[0] * width / 1000)\n",
    "    top = int(box[1] * height / 1000)\n",
    "    right = int(box[2] * width / 1000)\n",
    "    bottom = int(box[3] * height / 1000)\n",
    "    return [left, top, right, bottom]\n",
    "\n",
    "def extract_spans(labels, mask, kind):\n",
    "    \"\"\"\n",
    "    Ekstraherer spans av typen B-<kind>/I-<kind>, ignorerer pad-tokens.\n",
    "    \"\"\"\n",
    "    spans, cur = [], []\n",
    "    for idx, (lab, m) in enumerate(zip(labels, mask)):\n",
    "        if m == 0:\n",
    "            if cur:\n",
    "                spans.append(cur)\n",
    "                cur = []\n",
    "            continue\n",
    "        if lab == f\"B-{kind}\":\n",
    "            if cur:\n",
    "                spans.append(cur)\n",
    "            cur = [idx]\n",
    "        elif lab == f\"I-{kind}\" and cur:\n",
    "            cur.append(idx)\n",
    "        else:\n",
    "            if cur:\n",
    "                spans.append(cur)\n",
    "                cur = []\n",
    "    if cur:\n",
    "        spans.append(cur)\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51639cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellklasse\n",
    "class LayoutWithRelationModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    LayoutLMv3-basert modell med token-klassifisering + relasjonslag.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='microsoft/layoutlmv3-base',\n",
    "                 hidden_size=768, num_labels=5):\n",
    "        super().__init__()\n",
    "        self.layout = LayoutLMv3Model.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.token_classifier = torch.nn.Linear(hidden_size, num_labels)\n",
    "        rel_in = 4 * hidden_size + 1 + 2 * num_labels\n",
    "        self.rel_fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(rel_in, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, bbox, pixel_values,\n",
    "                attention_mask, entity_pairs=None):\n",
    "        out = self.layout(\n",
    "            input_ids=input_ids,\n",
    "            bbox=bbox,\n",
    "            pixel_values=pixel_values,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        hidden = self.dropout(out.last_hidden_state)\n",
    "        token_logits = self.token_classifier(hidden)\n",
    "        token_probs = torch.softmax(token_logits, dim=-1)\n",
    "\n",
    "        rel_logits = None\n",
    "        if entity_pairs is not None:\n",
    "            batch_scores = []\n",
    "            for b_idx, pairs in enumerate(entity_pairs):\n",
    "                h_b = hidden[b_idx]\n",
    "                p_b = token_probs[b_idx]\n",
    "                scores = []\n",
    "                for k_idx, v_idx in pairs:\n",
    "                    h_i = h_b[k_idx].mean(0)\n",
    "                    h_j = h_b[v_idx].mean(0)\n",
    "                    h_mul = h_i * h_j\n",
    "                    h_diff = h_i - h_j\n",
    "                    h_dot = torch.sum(h_i * h_j).unsqueeze(0)\n",
    "                    p_i = p_b[k_idx].mean(0)\n",
    "                    p_j = p_b[v_idx].mean(0)\n",
    "                    feats = torch.cat([h_i, h_j, h_mul, h_diff, h_dot, p_i, p_j], dim=0)\n",
    "                    scores.append(self.rel_fc(feats).squeeze())\n",
    "                batch_scores.append(torch.stack(scores))\n",
    "            max_len = max(s.size(0) for s in batch_scores)\n",
    "            padded = []\n",
    "            for s in batch_scores:\n",
    "                if s.size(0) < max_len:\n",
    "                    pad = s.new_zeros(max_len - s.size(0))\n",
    "                    s = torch.cat([s, pad], dim=0)\n",
    "                padded.append(s)\n",
    "            rel_logits = torch.stack(padded)\n",
    "        return {'token_logits': token_logits, 'rel_logits': rel_logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f389ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funksjon for å kjøre hele pipeline og tegne relasjoner\n",
    "def predict_relations_per_key(doc_id, threshold=0.5,\n",
    "                              model=None, processor=None,\n",
    "                              id2label=None, device=None,\n",
    "                              base_path=None):\n",
    "    # Load image og OCR\n",
    "    img_p = f\"{base_path}/images/{doc_id}.png\"\n",
    "    ocr_p = f\"{base_path}/ocrs/{doc_id}.json\"\n",
    "    image = Image.open(img_p).convert('RGB')\n",
    "    with open(ocr_p, 'r', encoding='utf-8') as f:\n",
    "        ocr = json.load(f)\n",
    "    page = ocr['pages'][0]\n",
    "    words = [w['text'] for w in page['words']]\n",
    "    raw = [w['bbox'] for w in page['words']]\n",
    "    W, H = page['width'], page['height']\n",
    "    norm = [normalize_bbox(b, W, H) for b in raw]\n",
    "\n",
    "    # Encoding\n",
    "    enc = processor(image, words, boxes=norm,\n",
    "                    return_tensors='pt', truncation=True, padding='max_length')\n",
    "    for k in enc:\n",
    "        enc[k] = enc[k].to(device)\n",
    "    token_boxes = enc['bbox'][0].cpu().tolist()\n",
    "    mask = enc['attention_mask'][0].cpu().tolist()\n",
    "\n",
    "    # 1) Token-prediksjoner\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out_t = model(input_ids=enc['input_ids'],\n",
    "                      bbox=enc['bbox'],\n",
    "                      pixel_values=enc['pixel_values'],\n",
    "                      attention_mask=enc['attention_mask'])\n",
    "    preds = out_t['token_logits'][0].argmax(-1).tolist()\n",
    "    labels = [id2label[i] for i in preds]\n",
    "    key_spans = extract_spans(labels, mask, 'KEY')\n",
    "    value_spans = extract_spans(labels, mask, 'VALUE')\n",
    "\n",
    "    # 2) Relasjonslogits\n",
    "    pairs = [(k, v) for k in key_spans for v in value_spans]\n",
    "    with torch.no_grad():\n",
    "        out_r = model(input_ids=enc['input_ids'],\n",
    "                      bbox=enc['bbox'],\n",
    "                      pixel_values=enc['pixel_values'],\n",
    "                      attention_mask=enc['attention_mask'],\n",
    "                      entity_pairs=[pairs])\n",
    "    rel_logits = out_r['rel_logits'][0]\n",
    "\n",
    "    # 3) Velg beste VALUE per KEY\n",
    "    best = {}\n",
    "    for idx, (k, v) in enumerate(pairs):\n",
    "        p = torch.sigmoid(rel_logits[idx]).item()\n",
    "        kt = tuple(k)\n",
    "        if kt not in best or p > best[kt][2]:\n",
    "            best[kt] = (k, v, p)\n",
    "    relations = [(k, v, p) for (k, v, p) in best.values() if p >= threshold]\n",
    "\n",
    "    # 4) Tegn spans og relasjoner\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    arrow_len = 15\n",
    "    angle = math.radians(25)\n",
    "\n",
    "    # Tegn alle KEY og VALUE\n",
    "    for k in key_spans:\n",
    "        for i in k:\n",
    "            draw.rectangle(unnormalize_box(token_boxes[i], W, H),\n",
    "                           outline='blue', width=2)\n",
    "    for v in value_spans:\n",
    "        for i in v:\n",
    "            draw.rectangle(unnormalize_box(token_boxes[i], W, H),\n",
    "                           outline='green', width=2)\n",
    "\n",
    "    # Tegn pil per KEY→beste VALUE\n",
    "    if not relations:\n",
    "        draw.text((10,10), 'Ingen relasjoner funnet',\n",
    "                  fill='orange', font=font)\n",
    "    else:\n",
    "        for k, v, p in relations:\n",
    "            kxs = [(b[0]+b[2])/2 for idx in k for b in [token_boxes[idx]]]\n",
    "            kys = [(b[1]+b[3])/2 for idx in k for b in [token_boxes[idx]]]\n",
    "            vxs = [(b[0]+b[2])/2 for idx in v for b in [token_boxes[idx]]]\n",
    "            vys = [(b[1]+b[3])/2 for idx in v for b in [token_boxes[idx]]]\n",
    "            kc = ((sum(kxs)/len(kxs))*W/1000, (sum(kys)/len(kys))*H/1000)\n",
    "            vc = ((sum(vxs)/len(vxs))*W/1000, (sum(vys)/len(vys))*H/1000)\n",
    "\n",
    "            dx, dy = vc[0]-kc[0], vc[1]-kc[1]\n",
    "            dist = math.hypot(dx, dy)\n",
    "            if dist > arrow_len:\n",
    "                ux, uy = dx/dist, dy/dist\n",
    "                tail = (kc[0], kc[1])\n",
    "                hb = (vc[0]-ux*arrow_len, vc[1]-uy*arrow_len)\n",
    "                draw.line([tail, hb], fill='red', width=2)\n",
    "            else:\n",
    "                hb = kc\n",
    "\n",
    "            ux, uy = (vc[0]-hb[0])/arrow_len, (vc[1]-hb[1])/arrow_len\n",
    "            lx = vc[0] - arrow_len*(ux*math.cos(angle) + uy*math.sin(angle))\n",
    "            ly = vc[1] - arrow_len*(uy*math.cos(angle) - ux*math.sin(angle))\n",
    "            rx = vc[0] - arrow_len*(ux*math.cos(angle) - uy*math.sin(angle))\n",
    "            ry = vc[1] - arrow_len*(uy*math.cos(angle) + ux*math.sin(angle))\n",
    "            draw.polygon([vc, (lx, ly), (rx, ry)], fill='red')\n",
    "            draw.text((vc[0]+3, vc[1]-10), f\"{p:.2f}\",\n",
    "                      fill='red', font=font)\n",
    "\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fcfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrasjon\n",
    "# Sett opp device, processor, model, id2label\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "processor = LayoutLMv3Processor.from_pretrained('microsoft/layoutlmv3-base')\n",
    "model = LayoutWithRelationModel().to(device)\n",
    "# NB: erstatt id2label med riktig mapping for ditt datasett\n",
    "id2label = {i: lab for lab, i in processor.tokenizer.get_vocab().items()}\n",
    "\n",
    "# Kjør prediksjon for et dokument\n",
    "predict_relations_per_key(\n",
    "    doc_id='f1689dd6-ac75-46ca-a32d-ae56d571dfa6',\n",
    "    threshold=0.5,\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    id2label=id2label,\n",
    "    device=device,\n",
    "    base_path='/content/drive/MyDrive/KVP10k-dataset/kvp10k/test'\n",
    ")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
