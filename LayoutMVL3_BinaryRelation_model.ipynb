{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/667029/KVP10k/blob/main/LayoutMVL3_BinaryRelation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VofLEluS_HIY"
      },
      "source": [
        "#Dokumentforståelse med LayoutLMv3 på KVP10k-datasettet\n",
        "\n",
        "Denne notebooken demonstrerer hvordan vi henter inn en preprossessert og tilpasset versjon av KVP10k-datasettet i Hugging Face-format, til å utføre **Key-Value Pair Extraction (KVP)** på  dokumentbilder.\n",
        "\n",
        "- Datasettet består av over 10k forretningsdokumenter, og inneholder blant annet dokumentbilder og tilhørende nøkkel-verdi-par, som brukes av denne fine-tuned modellen som utvikles her.\n",
        "\n",
        "- Sluttmålet er å utvikle og trene en ny modell til dokumentforståelse, ved å forstå **visuell layout**, **tekstlig innhold**, og **relasjoner mellom nøkler og verdier** i dokumentene.\n",
        "  - KVP-Extraction modellen som utvikles i denne notebooken er tenkt å brukes grunnmur i sluttmodellen, for å med stor sannsynlighet beherske å linke mellom nøkkel-verdi-par i ulike dokumenter.\n",
        "\n",
        "LayoutLMv3 er en multi-modal modell designet for å kombinere tekst, layout og annen bilde-informasjon\n",
        "\n",
        "---\n",
        "\n",
        "###**Notbooken dekker følgende steg**:\n",
        "\n",
        "1. Installasjon av de nødendige biblioteker\n",
        "2. Lasting av forhåndsprosessert datasett\n",
        "3. Tokenisering av tekst og input-formatering med Layout sin Processor\n",
        "- 3.1 Logikk for å anngi predikerte BIO-labels til dokumentets bbox'es\n",
        "4. Trening av modell for token-klassifisering\n",
        "5. Evaluering og lagring av modell i Drive\n",
        "6. Visualisering av modell under inferense\n",
        "\n",
        "---\n",
        "\n",
        "###**LayoutLMv3Processor - gjør følgende**:\n",
        "1. Tekst-tokenisering: Tekst fra dokumentet tokeniseres.\n",
        "2. Token-connection: Hvert token kobles til en bounding box (bbox) på dokumentet, gjennom *boxes*-parmeteret som inneholder (x0,y0,x1,y1)-kordinater til hvert token.\n",
        "3. Image-embedding: Dokumentbildet skaleres og legges og blir input til modellen\n",
        "4. Label-alignment: Hvert token får en BIO-label, som brukes under modellens token-klassifisering\n",
        "\n",
        "Tokeniseringen handler om å forvandle dokumentet til tokens med alle nødvendige modaliteter (tekst, layout og bilde) slik at modellen lærer sammenhengen mellom dem gjennom trening.\n",
        "\n",
        "**Det brukes BIO-tagger, og dette er hva det står for:**\n",
        " - B --> Begin: første token i en entitet.\n",
        " - I --> Inside: inne i en entitet.\n",
        " - O --> Outside: tokenen er ikke en del av noen entitet\n",
        "\n",
        "f.eks.\n",
        "  - Tokens:  [\"Name\", \"of\", \"buyer\", \":\", \"Ole\", \"Martin\", \"Lystadmoen\"]\n",
        "  - Labels:  [\"B-KEY\", \"I-KEY\", \"I-KEY\", \"O\", \"B-VALUE\", \"I-VALUE\", \"I-VALUE\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0NSOqNmukkk"
      },
      "source": [
        "# Dataset - forståelse\n",
        "\n",
        "**Innhold i train/-mappen i KVP10k:**\n",
        "_____\n",
        "  - *images*/ --> .png bilder av hvert dokument. Visuell input for modellen.\n",
        "    - Det modellen \"ser\".\n",
        "_____\n",
        "\n",
        "  - *ocrs*/ --> JSON-filer med **words** og **bboxes** for hvert dokument. Gir tekst og posisjoner fra OCR, og brukes sammen med images.\n",
        "    - Det modellen \"leser\" (tokens og posisjonene deres).\n",
        "\n",
        "_____\n",
        "\n",
        "  - *gts*/ --> JSON-filer med KVPs og tilhørende bboxes. Inneholder hvilke keys og values som hører sammen.\n",
        "    - Det som lærer modellen hvilke tokens som er nøkler, verdier, og hvilket som er koblet sammen.\n",
        "_____\n",
        "\n",
        "  - *items*/ --> JSON-filer med annotasjoner og layout-objs (rektangler, linker, etiketter)\n",
        "    - tilleggsinformasjon\n",
        "    - ikke viktig i for EE\n",
        "    - Helt nødvendig i RE-delen av dette prosjektet\n",
        "_____"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "TqejcrWXvnoL"
      },
      "outputs": [],
      "source": [
        "#transformers: Hugging Face bibliotek som gir tilgang til LayoutLMv3\n",
        "#datasets: For håndtering av dataset i Huggig Face-format\n",
        "#seqeval: evalueringsbibliotek for sekvensmerking, brukes for måle metrikker for i dette tilfelle BIO-tagging\n",
        "!pip install -q transformers datasets seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Av-n3h6jaou3"
      },
      "outputs": [],
      "source": [
        "#Håndterer ulike metrikker inkl. integrasjon med seqeval\n",
        "!pip install -q evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GE27SIYc2Y2y"
      },
      "outputs": [],
      "source": [
        "import os              #navigere mapper og filer, hente filbaner\n",
        "from PIL import Image  #åpne, vise og manipulere bilder\n",
        "import json            #lese/skrive til JSON-filer\n",
        "from transformers import LayoutLMv3Processor\n",
        "import torch           #modellens input-format for data\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Uup0eV5_usd",
        "outputId": "4e6ec274-d9a6-40a7-cf80-7a79786d157e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW4eqj9o2trD",
        "outputId": "c25b0711-6376-4799-dbd8-57cb88b4779c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train', 'test']\n"
          ]
        }
      ],
      "source": [
        "base_path = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/\"\n",
        "print(os.listdir(base_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WYm7ncZw_lSW"
      },
      "outputs": [],
      "source": [
        "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False) # <-- Viktig fordi vi allerede har utført OCR på bildet og har tekst og bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RsRz3cC2_8mj"
      },
      "outputs": [],
      "source": [
        "# Mapping fra tekstlige BIO-labels til tall som modellen bruker\n",
        "label_map = {\n",
        "    \"O\": 0,\n",
        "    \"B-KEY\": 1,\n",
        "    \"I-KEY\": 2,\n",
        "    \"B-VALUE\": 3,\n",
        "    \"I-VALUE\": 4,\n",
        "}\n",
        "\n",
        "# Funksjon for å skalere bounding boxes til 0-1000 (som LayoutLMv3 krever)\n",
        "def normalize_bbox(bbox, width, height):\n",
        "  return [\n",
        "      int(1000 * (bbox[0] /width)),\n",
        "      int(1000 * (bbox[1] / height)),\n",
        "      int(1000 * (bbox[2] / width)),\n",
        "      int(1000 * (bbox[3] / height))\n",
        "  ]\n",
        "\n",
        "\n",
        "def assign_label_for_box(box, boxes, label_type):\n",
        "  \"\"\"Returnerer liste med (index, label) for tokens som overlapper box\"\"\"\n",
        "  overlaps = []\n",
        "  for i, token_box in enumerate(boxes):\n",
        "    if box_overlap(box, token_box) > 0:\n",
        "      overlaps.append(i)\n",
        "\n",
        "  overlaps = sorted(overlaps)\n",
        "\n",
        "  labeled = []\n",
        "  for j, idx in enumerate(overlaps):\n",
        "    tag = f\"B-{label_type}\" if j == 0 else f\"I-{label_type}\"\n",
        "    labeled.append((idx, tag))\n",
        "\n",
        "  return labeled\n",
        "\n",
        "\n",
        "#Sjekker om OCR-boksen overlapper med GTS(key/value)-boksen.\n",
        "#Ved overlapp hører de til hverandre.\n",
        "def box_overlap(box1, box2):\n",
        "  x0 = max(box1[0], box2[0])\n",
        "  y0 = max(box1[1], box2[1])\n",
        "  x1 = min(box1[2], box2[2])\n",
        "  y1 = min(box1[3], box2[3])\n",
        "  return max(0, x1 - x0) * max(0, y1 - y0)\n",
        "\n",
        "\n",
        "# Funksjon for å generere BIO-labels fra gts (ground truth).\n",
        "# Lager en BIO-label for hvert token basert på om det overlapper med en key- eller value-boks fra GTS.\n",
        "# Matcher hvert token fra OCR (word + bbox) mot key/value-bbokser fra gts:\n",
        "# --> Token overlapper en nøkkelboks: B-KEY eller I-KEY\n",
        "# --> Token overlapper en verdiboks: B-VALUE eller I-VALUE\n",
        "# --> Ellers: O\n",
        "def iob_from_kvps(words, boxes, kvps):\n",
        "  labels = [\"O\"] * len(words)\n",
        "\n",
        "  #Gå igjennom alle key-value-pairs\n",
        "  for kvp in kvps:\n",
        "    if \"key\" in kvp and \"bbox\" in kvp[\"key\"]:\n",
        "      key_bbox = kvp[\"key\"][\"bbox\"]\n",
        "      for idx, tag in assign_label_for_box(key_bbox, boxes, \"KEY\"):\n",
        "        labels[idx] = tag\n",
        "\n",
        "    if \"value\" in kvp and \"bbox\" in kvp[\"value\"]:\n",
        "      value_box = kvp[\"value\"][\"bbox\"]\n",
        "      for idx, tag in assign_label_for_box(value_box, boxes, \"VALUE\"):\n",
        "        labels[idx] = tag\n",
        "\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94wyjeWiRmJG",
        "outputId": "9f4c3179-50ce-4f20-dc14-1a70976802d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lrw------- 1 root root 0 Apr 20 20:52 /content/drive/MyDrive/KVP10k_processed_ready -> /content/drive/.shortcut-targets-by-id/1NbM9cwuCpZGK4W3yzn5hIDmqyp3uULqw/KVP10k_processed_ready\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content/drive/MyDrive/KVP10k_processed_ready\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl8UG_z9fMpK"
      },
      "source": [
        "#Innlasting av et allerede pre-prossesert KVP10k-dataset spesielt utviklet for LayoutLMv3 (KVP-extraction).\n",
        "##Ikke kjør denne!\n",
        "\n",
        "NB: Dette prosessen gjøres i en annen notebook, vi henter inn resultatet her for å spare notebooken for plass og ryddighet.\n",
        "\n",
        "Datasettet som lastes inn er på omlag 8600 dokumenter da det er antall dokumenter med ground-truths (gts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrLS234HQhcG",
        "outputId": "b515e793-5883-41cc-9754-f304094446e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from datasets import load_from_disk\n",
        "\n",
        "# Monter Drive (hvis du ikke har gjort det)\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Last inn dataset fra riktig path\n",
        "dataset = load_from_disk(\"/content/drive/MyDrive/KVP10k_processed_ready/dataset_all_gts\")\n",
        "\n",
        "# Hent splits\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"eval\"]\n",
        "test_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2e38f72f7d0940d39302cdc1065bc6fd",
            "9cf0641365cd44a8aa8442b9f96f0e86",
            "2e3d589b62ea42069995d48ce568ba08",
            "7b214af6b9e44c278ffb65f22e4aab2b",
            "6030dd5cdd2947509bcebc9c37f5102a",
            "029637c1faf84f25bf2a72ba7394c023",
            "ce215149d3184b438bbe08ff4da3238b",
            "ae183f5cafb2471ab6f6d89671a3ee96",
            "9047638760d04fccacf29ea5f07609e1",
            "6cd980b7da6649ac9c6beb5402e30462",
            "d998de5c800c4212b8b5bcc30332836f",
            "5df32418f5894b3384c85664d14b3bdd",
            "b336fb536dc14ba3a508e19b3f6e55f3",
            "6b63067af4f74d3f9b7417e8e3dbb58e",
            "f09e0705ed21489e9644ab24620da3b1",
            "fb3ee83578c1482488b61d631a7a861f",
            "25e8c49ea8d1493bbd7cc221dfc50c10",
            "044dce4c059647819efb02d254d2fc19",
            "c6ddffde07214109ac7f9ed95f593046",
            "8bc284696be54b70bc63a8047467484f",
            "ea4f00e13c0e41aea4b7dbdd6b4f6d19",
            "ca3155b4efef4f4a9867217c857cebc1",
            "57030de9dd074234a1a3d4d94fc5ae81",
            "216496bf28b0438e80fdbc2f5d4a5bb3",
            "30b38db6d9ca4dc786d82f85aa4692b9",
            "90279cc68ace4c77838dd9bfa6c7797b",
            "54f86307e15a482ab8be56db4f56dd71",
            "cc506c74694d490ca8dfa8b6b53f62d2",
            "c6a9cc8d8c3142b3ab7fdc3166a55556",
            "014fefe32b524a009a54852170ef464e",
            "e37d1b3f14204b47a7405dc92aafb035",
            "67a07d334961462a9d607819488499cf",
            "eb87865008e143e5aa593482b699ba81"
          ]
        },
        "id": "IEkZt_FZWeuV",
        "outputId": "2e2e39b8-b101-4971-8ad2-2c3863cf9500"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6273 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e38f72f7d0940d39302cdc1065bc6fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1569 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5df32418f5894b3384c85664d14b3bdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/828 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57030de9dd074234a1a3d4d94fc5ae81"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from evaluate import load\n",
        "metric = load(\"seqeval\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "label_list = [\"O\", \"B-KEY\", \"I-KEY\", \"B-VALUE\", \"I-VALUE\"]\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "def add_relation_labels(example):\n",
        "    rel_h = []\n",
        "    rel_t = []\n",
        "    rel_labels = []\n",
        "\n",
        "    words = example.get(\"words\", [])  # Get words, or empty list if not found\n",
        "    word_labels = example.get(\"ner_tags\", [])  # Get ner_tags if \"labels\" not found\n",
        "    kvps = example.get(\"kvps_list\", [])\n",
        "\n",
        "    key_token_map = {}\n",
        "    value_token_map = {}\n",
        "\n",
        "    for idx, label_id in enumerate(word_labels):\n",
        "        label = id2label.get(label_id, \"O\")\n",
        "        if label.startswith(\"B-KEY\"):\n",
        "            key_token_map.setdefault(len(key_token_map), idx)\n",
        "        elif label.startswith(\"B-VALUE\"):\n",
        "            value_token_map.setdefault(len(value_token_map), idx)\n",
        "\n",
        "    entity_pairs = []  # Create entity_pairs for this example\n",
        "    for rel_id, kvp in enumerate(kvps):\n",
        "        key_idx = key_token_map.get(rel_id)\n",
        "        val_idx = value_token_map.get(rel_id)\n",
        "\n",
        "        # For relation extraction, we need to find spans of key and value tokens\n",
        "        key_idxs = []\n",
        "        val_idxs = []\n",
        "\n",
        "        if key_idx is not None:\n",
        "            key_idxs.append(key_idx)\n",
        "            # Try to find consecutive \"I-KEY\" tokens\n",
        "            i = key_idx + 1\n",
        "            while i < len(word_labels) and id2label.get(word_labels[i], \"O\").startswith(\"I-KEY\"):\n",
        "                key_idxs.append(i)\n",
        "                i += 1\n",
        "\n",
        "        if val_idx is not None:\n",
        "            val_idxs.append(val_idx)\n",
        "            # Try to find consecutive \"I-VALUE\" tokens\n",
        "            i = val_idx + 1\n",
        "            while i < len(word_labels) and id2label.get(word_labels[i], \"O\").startswith(\"I-VALUE\"):\n",
        "                val_idxs.append(i)\n",
        "                i += 1\n",
        "\n",
        "        if key_idxs and val_idxs:  # Only add pairs if both key and value were found\n",
        "            entity_pairs.append((key_idxs, val_idxs))\n",
        "            rel_h.append(key_idx)\n",
        "            rel_t.append(val_idx)\n",
        "            rel_labels.append(1)  # 1 = real relation\n",
        "    #---Endre fra rel_h[0] siden list comprehension har blitt lagt til på linje 23\n",
        "    example[\"rel_h\"] = rel_h\n",
        "    example[\"rel_t\"] = rel_t\n",
        "    example[\"rel_labels\"] = rel_labels\n",
        "\n",
        "    # Store entity_pairs in the example\n",
        "    example[\"entity_pairs\"] = entity_pairs\n",
        "\n",
        "    # Handle cases where no relations were found:\n",
        "    # For training, it's helpful to have at least one pair, even if it's a \"dummy\" relation\n",
        "    if not entity_pairs:\n",
        "        #example[\"entity_pairs\"] = [([0], [1])]  # Dummy pair of [CLS] and the next token (usually a separator)\n",
        "        #example[\"rel_labels\"] = [0]  # Label this dummy pair as \"no relation\" (0)\n",
        "        example[\"rel_h\"] = []\n",
        "        example[\"rel_t\"] = []\n",
        "        example[\"entity_pairs\"] = [] #Dummy pair of [CLS] and the next token (usually a separator)\n",
        "        example[\"rel_labels\"] = [] # Label this dummy pair as \"no relation\" (0)\n",
        "\n",
        "    return example\n",
        "\n",
        "\n",
        "# Assuming train_dataset, eval_dataset, and test_dataset are already loaded\n",
        "train_dataset = train_dataset.map(add_relation_labels)\n",
        "eval_dataset = eval_dataset.map(add_relation_labels)\n",
        "test_dataset = test_dataset.map(add_relation_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Ya332BhmGLt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa8db14-936e-43bd-b995-ab02027aecb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              " 'bbox': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
              " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              " 'rel_h': Sequence(feature=Value(dtype='null', id=None), length=-1, id=None),\n",
              " 'rel_t': Sequence(feature=Value(dtype='null', id=None), length=-1, id=None),\n",
              " 'rel_labels': Sequence(feature=Value(dtype='null', id=None), length=-1, id=None),\n",
              " 'entity_pairs': Sequence(feature=Value(dtype='null', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "train_dataset.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "collapsed": true,
        "id": "EB3kZmZpTu-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2e1a8a-1de4-47db-fba2-efbce6072410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel_values torch.Size([3, 224, 224])\n",
            "input_ids torch.Size([512])\n",
            "attention_mask torch.Size([512])\n",
            "bbox torch.Size([512, 4])\n",
            "labels torch.Size([512])\n",
            "rel_h 0\n",
            "rel_t 0\n",
            "rel_labels 0\n",
            "entity_pairs 0\n"
          ]
        }
      ],
      "source": [
        "example = train_dataset[0]\n",
        "for k,v in example.items():\n",
        "    try:\n",
        "        print(k, v.shape)\n",
        "    except AttributeError:\n",
        "        print(k, len(v))  # Print length of list instead of shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "collapsed": true,
        "id": "GTN1cXBYTynu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "47351fa5-c3b3-434c-e55a-dab1692ba1a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Date Net Zone/Syscode Time Spot Name Len Line Rate Flag 10-722 HIST L Middlesx Smrst Cty Zone 1302/1302 4:44PM CLFTVNJO702H 30 48 $73.00 10-722 HIST L Middlesx Smrst Cty Zone 1302/1302 7:45PM CLFTVNJO702H 30 487 $90.00 10-722 HIST L Middlesx Smrst Cty Zone 1302/1302 11:46PM CLFTVNJO702H 30 487 $90.00 10-722 AEN Morris County Zone 1305/1305 2:13PM CLFTVNJO702H 30 488 $21.00 10-722 AEN Morris County Zone 1305/1305 5:40PM CLFTVNJO702H 30 489 $49.00 10-722 AEN Morris County Zone 1305/1305 7:44PM CLFTVNJO702H 30 490 $59.00 10-722 AEN Morris County Zone 1305/1305 10:48PM CLFTVNJO702H 30 490 $59.00 10-722 CNN Morris County Zone 1305/1305 8:29AM CLFTVNJO702H 30 491 $73.00 10-722 CNN Morris County Zone 1305/1305 3:30PM CLFTVNJO702H 30 492 $65.00 10-722 CNN Morris County Zone 1305/1305 4:26PM CLFTVNJO702H 30 493 $121.00 10-722 CNN Morris County Zone 1305/1305 9:27PM CLFTVNJO702H 30 494 $164.00 10-722 DISC Morris County Zone 1305/1305 9:25AM CLFTVNJO702H 30 495 $21.00 10-722 DISC Morris County Zone 1305/1305 6:41PM CLFTVNJO702H 30 496 $49.00 10-722 DISC Morris County Zone 1305/1305 9:42PM CLFTVNJO702H 30 497 $59.00 10-722 DISC Morris County Zone 1305/1305 11:49PM CLFTVNJO702H 30 497 $59.00 10-722 FXNC</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "processor.tokenizer.decode(train_dataset[0][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "collapsed": true,
        "id": "hhU1sClvWGOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27faaaf8-1596-4291-ca1a-2b107d893cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> -100\n",
            " Date 0\n",
            " Net 0\n",
            " Zone 0\n",
            "/ -100\n",
            "Sys -100\n",
            "code -100\n",
            " Time 0\n",
            " Spot 0\n",
            " Name 0\n",
            " Len 0\n",
            " Line 0\n",
            " Rate 0\n",
            " Flag 0\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " H 0\n",
            "IST -100\n",
            " L 0\n",
            " Middles 0\n",
            "x -100\n",
            " Sm 0\n",
            "r -100\n",
            "st -100\n",
            " C 0\n",
            "ty -100\n",
            " Zone 0\n",
            " 130 0\n",
            "2 -100\n",
            "/ -100\n",
            "130 -100\n",
            "2 -100\n",
            " 4 0\n",
            ": -100\n",
            "44 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 48 0\n",
            " $ 0\n",
            "73 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " H 0\n",
            "IST -100\n",
            " L 0\n",
            " Middles 0\n",
            "x -100\n",
            " Sm 0\n",
            "r -100\n",
            "st -100\n",
            " C 0\n",
            "ty -100\n",
            " Zone 0\n",
            " 130 0\n",
            "2 -100\n",
            "/ -100\n",
            "130 -100\n",
            "2 -100\n",
            " 7 0\n",
            ": -100\n",
            "45 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 48 0\n",
            "7 -100\n",
            " $ 0\n",
            "90 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " H 0\n",
            "IST -100\n",
            " L 0\n",
            " Middles 0\n",
            "x -100\n",
            " Sm 0\n",
            "r -100\n",
            "st -100\n",
            " C 0\n",
            "ty -100\n",
            " Zone 0\n",
            " 130 0\n",
            "2 -100\n",
            "/ -100\n",
            "130 -100\n",
            "2 -100\n",
            " 11 0\n",
            ": -100\n",
            "46 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 48 0\n",
            "7 -100\n",
            " $ 0\n",
            "90 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " A 0\n",
            "EN -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 2 0\n",
            ": -100\n",
            "13 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 4 0\n",
            "88 -100\n",
            " $ 0\n",
            "21 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " A 0\n",
            "EN -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 5 0\n",
            ": -100\n",
            "40 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 4 0\n",
            "89 -100\n",
            " $ 0\n",
            "49 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " A 0\n",
            "EN -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 7 0\n",
            ": -100\n",
            "44 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 490 0\n",
            " $ 0\n",
            "59 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " A 0\n",
            "EN -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 10 0\n",
            ": -100\n",
            "48 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 490 0\n",
            " $ 0\n",
            "59 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " CNN 0\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 8 0\n",
            ": -100\n",
            "29 -100\n",
            "AM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "1 -100\n",
            " $ 0\n",
            "73 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " CNN 0\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 3 0\n",
            ": -100\n",
            "30 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "2 -100\n",
            " $ 0\n",
            "65 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " CNN 0\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 4 0\n",
            ": -100\n",
            "26 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "3 -100\n",
            " $ 0\n",
            "121 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " CNN 0\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 9 0\n",
            ": -100\n",
            "27 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "4 -100\n",
            " $ 0\n",
            "164 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " DIS 0\n",
            "C -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 9 0\n",
            ": -100\n",
            "25 -100\n",
            "AM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 4 0\n",
            "95 -100\n",
            " $ 0\n",
            "21 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " DIS 0\n",
            "C -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 6 0\n",
            ": -100\n",
            "41 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 4 0\n",
            "96 -100\n",
            " $ 0\n",
            "49 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " DIS 0\n",
            "C -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 9 0\n",
            ": -100\n",
            "42 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "7 -100\n",
            " $ 0\n",
            "59 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " DIS 0\n",
            "C -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 11 0\n",
            ": -100\n",
            "49 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "7 -100\n",
            " $ 0\n",
            "59 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " FX 0\n",
            "NC -100\n",
            "</s> -100\n"
          ]
        }
      ],
      "source": [
        "for id, label in zip(train_dataset[0][\"input_ids\"], train_dataset[0][\"labels\"]):\n",
        "  print(processor.tokenizer.decode([id]), label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "WmYZ6LnbaWTv"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "metric = load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "0nAjhdhwa1fh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "label_list = [\"O\", \"B-KEY\", \"I-KEY\", \"B-VALUE\", \"I-VALUE\"]\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "\n",
        "    # === Token classification metrics (BIO tagging)\n",
        "    token_preds = predictions[\"token_logits\"]\n",
        "    token_labels = labels[\"labels\"]\n",
        "\n",
        "    token_preds = np.argmax(token_preds, axis=2)\n",
        "    true_preds = [\n",
        "        [id2label[p] for (p, l) in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(token_preds, token_labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(token_preds, token_labels)\n",
        "    ]\n",
        "\n",
        "    bio_result = metric.compute(predictions=true_preds, references=true_labels)\n",
        "\n",
        "    # === Relation classification metrics\n",
        "    rel_preds = predictions[\"rel_logits\"]\n",
        "    rel_labels = labels[\"rel_labels\"]\n",
        "\n",
        "    if rel_preds is not None and rel_labels is not None:\n",
        "        rel_preds = np.argmax(rel_preds, axis=1)\n",
        "        rel_labels = np.array(rel_labels)\n",
        "\n",
        "        rel_acc = accuracy_score(rel_labels, rel_preds)\n",
        "        rel_f1 = f1_score(rel_labels, rel_preds, average=\"macro\")\n",
        "        rel_precision = precision_score(rel_labels, rel_preds, average=\"macro\")\n",
        "        rel_recall = recall_score(rel_labels, rel_preds, average=\"macro\")\n",
        "    else:\n",
        "        rel_acc = rel_f1 = rel_precision = rel_recall = 0.0\n",
        "\n",
        "    return {\n",
        "        # BIO tagging\n",
        "        \"precision\": bio_result[\"overall_precision\"],\n",
        "        \"recall\": bio_result[\"overall_recall\"],\n",
        "        \"f1\": bio_result[\"overall_f1\"],\n",
        "        \"accuracy\": bio_result[\"overall_accuracy\"],\n",
        "\n",
        "        # Relation prediction\n",
        "        \"rel_acc\": rel_acc,\n",
        "        \"rel_f1\": rel_f1,\n",
        "        \"rel_precision\": rel_precision,\n",
        "        \"rel_recall\": rel_recall\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrotUlpib9Mh"
      },
      "source": [
        "#Innlasting av modell, valg av hyperparams og modell-argumenter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "_DzA5KFAdeA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import LayoutLMv3Model\n",
        "\n",
        "class LayoutLMv3WithBinaryRelation(nn.Module):\n",
        "    def __init__(self, model_name=\"microsoft/layoutlmv3-base\", hidden_size=768, num_labels=5):\n",
        "        super().__init__()\n",
        "        self.layoutlmv3 = LayoutLMv3Model.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # Token classification head\n",
        "        self.token_classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        # Relation classification head\n",
        "        self.rel_fc = nn.Sequential(\n",
        "            nn.Linear(4 * hidden_size + 1, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, bbox, attention_mask, entity_pairs=None, labels=None, rel_labels=None):\n",
        "        outputs = self.layoutlmv3(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask)\n",
        "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        # Token classification logits\n",
        "        token_logits = self.token_classifier(sequence_output)\n",
        "\n",
        "        rel_logits = None\n",
        "        rel_loss = None\n",
        "        if entity_pairs is not None and entity_pairs and entity_pairs[0]:\n",
        "            batch_rel_logits = []\n",
        "            for batch_idx, pairs in enumerate(entity_pairs):\n",
        "                logits = []\n",
        "                for (head_idxs, tail_idxs) in pairs:\n",
        "                    h = sequence_output[batch_idx]\n",
        "                    head = h[head_idxs].mean(dim=0)\n",
        "                    tail = h[tail_idxs].mean(dim=0)\n",
        "\n",
        "                    h_mul = head * tail\n",
        "                    h_diff = head - tail\n",
        "                    h_dot = torch.sum(head * tail).unsqueeze(0)\n",
        "\n",
        "                    feats = torch.cat([head, tail, h_mul, h_diff, h_dot], dim=0)\n",
        "                    logit = self.rel_fc(feats).squeeze()\n",
        "                    logits.append(logit)\n",
        "                batch_rel_logits.append(torch.stack(logits))\n",
        "            rel_logits = torch.stack(batch_rel_logits)\n",
        "\n",
        "            if rel_labels is not None:\n",
        "                loss_fn = nn.BCEWithLogitsLoss()\n",
        "                rel_loss = loss_fn(rel_logits, rel_labels)\n",
        "        else:\n",
        "            rel_logits = torch.tensor([])\n",
        "\n",
        "        token_loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            # reshape to (batch*seq_len, num_labels)\n",
        "            token_loss = loss_fct(token_logits.view(-1, token_logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        loss = None\n",
        "        if token_loss is not None and rel_loss is not None:\n",
        "            loss = token_loss + rel_loss\n",
        "        elif token_loss is not None:\n",
        "            loss = token_loss\n",
        "        elif rel_loss is not None:\n",
        "            loss = rel_loss\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"token_logits\": token_logits,\n",
        "            \"rel_logits\": rel_logits\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "hg8bMcM5dmYW"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/layoutlmv3_finetuned_kvp10k\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    report_to=\"tensorboard\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=500,\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "\n",
        "model = LayoutLMv3WithBinaryRelation()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4gp7_LQdmII"
      },
      "source": [
        "#Trainer oppsett\n",
        "Inneholder:\n",
        "  - Modellen (LayoutLMv3ForTokenClassification)\n",
        "  - Args (hyperparametre som: epochs, batch_size, lr, lr_scheduler,    regularisering, eval_steps, metrics)\n",
        "  - Datasetsplit (train, eval)\n",
        "  - Tokenizer (from processor)\n",
        "  - Collator (litt usikker på denne)\n",
        "  - Metrikker for modellen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "DjX4VR2lV6bI"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "import torch.nn.functional as F\n",
        "from transformers.data.data_collator import default_data_collator\n",
        "\n",
        "class CombinedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        outputs = model(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            bbox=inputs[\"bbox\"],\n",
        "            attention_mask=inputs.get(\"attention_mask\"),\n",
        "            labels=inputs.get(\"labels\"),\n",
        "            rel_labels=inputs.get(\"rel_labels\"),\n",
        "            entity_pairs=inputs.get(\"entity_pairs\")\n",
        "        )\n",
        "\n",
        "        loss = outputs[\"loss\"]\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "\n",
        "def combined_data_collator(features):\n",
        "    batch = default_data_collator(features)\n",
        "    if \"rel_labels\" in batch:\n",
        "        batch[\"rel_labels\"] = batch[\"rel_labels\"].float()\n",
        "    batch[\"entity_pairs\"] = [f[\"entity_pairs\"] for f in features]\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "endgETwXet1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61326ce0-94bf-4b21-d9ca-5e8100dacf31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-97-e07de4bde8d3>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, EarlyStoppingCallback\n",
        "training_args\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    data_collator=combined_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqSzsM9cdjCU"
      },
      "source": [
        "#Trening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "collapsed": true,
        "id": "5erU_T1xfOLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "b13d1d7e-da31-43fd-a8f3-98e278059c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1575: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='6276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 101/6276 00:09 < 10:09, 10.13 it/s, Epoch 0.06/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='6276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 101/6276 00:09 < 10:21, 9.93 it/s, Epoch 0.06/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='786' max='393' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [393/393 05:56]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "tuple indices must be integers or slices, not str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2625\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msteps_skipped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2627\u001b[0;31m                         self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2628\u001b[0m                             \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m                             \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3094\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3096\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3097\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3044\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3045\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3046\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4153\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4154\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4155\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4156\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4441\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"losses\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_losses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_inputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"inputs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4443\u001b[0;31m             metrics = self.compute_metrics(\n\u001b[0m\u001b[1;32m   4444\u001b[0m                 \u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4445\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-85-4e9c7ab81a8d>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# === Token classification metrics (BIO tagging)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtoken_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtoken_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "e36vlg1KYwau"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6dOcIbfcOOf"
      },
      "source": [
        "#Evaluering på test-datasettet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EsTmPLyGdeqQ"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(test_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43YLXmgzcR41"
      },
      "source": [
        "#Lagring av beste Modell (i Drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "judb3GpS6o4Y"
      },
      "outputs": [],
      "source": [
        "# Angi en mappe i Drive (eller lokalt hvis du vil kopiere senere)\n",
        "output_dir = \"/content/drive/MyDrive/layoutlmv3_kvp10k_model_full_dataset\"\n",
        "\n",
        "# Lagre modell og tokenizer\n",
        "trainer.save_model(output_dir)\n",
        "processor.save_pretrained(output_dir)  # dette lagrer både tokenizer + feature extracto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJinDzWcwpUL"
      },
      "source": [
        "#INFERENCE\n",
        "Laster inn beste fine-tuned modell og dens tilhørende processor fra Drive, samt tilleggsinformasjon som kreves av processoren.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gftv6oBQ8Rjl"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor, AutoModelForTokenClassification\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/layoutlmv3_kvp10k_model_full_dataset\"\n",
        "\n",
        "# Last inn modellen (med dine finetunede vekter)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "# Last inn processor (inneholder både tokenizer og feature extractor)\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "\n",
        "# Sett modellen til riktig device (valgfritt, men vanlig)\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "id2label = model.config.id2label\n",
        "id2label = model.config.id2label\n",
        "label_map = label2id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzzMQnpi0xUz"
      },
      "source": [
        "#Kode prediksjon og visualisering av dette\n",
        "###*Tokenisering og input-prosessering med Layout sin Processor ved inference*\n",
        "Processor brukes her til å gjøre om tekst, bboxes, og bilde til format modell krever. Dette inkl:\n",
        "- Tokenisering\n",
        "- Normalisering av bboxes tilhørende hvert token\n",
        "- Skalering av bilde\n",
        "- Generering av input-tensorer\n",
        "\n",
        "NB: Denne prosessen gjøres allerede i Data_Processor notebooken som ferdigstilte datasettet for **denne** notebooken. Selve prosessen er dermed nesten indentisk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3DDG0gwdC0Y"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "\n",
        "#Nødvendig for å plassere boksene på originalt-format på bilde-dokumentet\n",
        "def unnormalize_box(bbox, width, height):\n",
        "    return [\n",
        "        width * (bbox[0] / 1000),\n",
        "        height * (bbox[1] / 1000),\n",
        "        width * (bbox[2] / 1000),\n",
        "        height * (bbox[3] / 1000),\n",
        "    ]\n",
        "\n",
        "def predict_and_visualize(doc_id, show_gt=True):\n",
        "    base_path = \"/content/drive/MyDrive/DAT255/KVP10k-dataset/kvp10k/test\"\n",
        "\n",
        "    # === Last inn bilde og metadata\n",
        "    image_path = f\"{base_path}/images/{doc_id}.png\"\n",
        "    ocr_path = f\"{base_path}/ocrs/{doc_id}.json\"\n",
        "    gt_path = f\"{base_path}/gts/{doc_id}.json\"\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ocr_data = json.load(f)\n",
        "    with open(gt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        gt_data = json.load(f)\n",
        "\n",
        "    # === Hent tekst og bokser\n",
        "    page = ocr_data[\"pages\"][0]\n",
        "    words = [w[\"text\"] for w in page[\"words\"]]\n",
        "    raw_boxes = [w[\"bbox\"] for w in page[\"words\"]]\n",
        "    width, height = page[\"width\"], page[\"height\"]\n",
        "    norm_boxes = [normalize_bbox(b, width, height) for b in raw_boxes]\n",
        "\n",
        "    # === Lag word_labels fra GT\n",
        "    string_labels = iob_from_kvps(words, raw_boxes, gt_data[\"kvps_list\"])\n",
        "    word_labels = [label_map[l] for l in string_labels]\n",
        "\n",
        "    # === Encoding for modellen\n",
        "    encoding = processor(\n",
        "        image,\n",
        "        words,\n",
        "        boxes=norm_boxes,\n",
        "        word_labels=word_labels,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    inputs = {k: v.to(model.device) for k, v in encoding.items()}\n",
        "\n",
        "    # === Modellprediksjon\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"].squeeze().tolist()\n",
        "    labels = encoding[\"labels\"].squeeze().tolist()\n",
        "    bboxes = encoding[\"bbox\"].squeeze().tolist()\n",
        "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
        "\n",
        "    # === Unnormalize bboxes\n",
        "    unnorm_boxes = [unnormalize_box(b, width, height) for b in bboxes]\n",
        "    tokens = [processor.tokenizer.decode([tid]) for tid in input_ids]\n",
        "\n",
        "    # === Filtrer vekk padding og spesialtokens\n",
        "    filtered = [\n",
        "        (token, id2label[label], id2label[pred], box)\n",
        "        for token, label, pred, box in zip(tokens, labels, predictions, unnorm_boxes)\n",
        "        if label != -100 and token not in [\"[PAD]\", \"[CLS]\", \"[SEP]\"]\n",
        "    ]\n",
        "\n",
        "    # === Tegn prediksjoner\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "    def iob_to_label(label):\n",
        "        return label[2:].lower() if label.startswith((\"B-\", \"I-\")) else \"other\"\n",
        "\n",
        "    label2color = {\n",
        "        \"key\": \"blue\",\n",
        "        \"value\": \"green\",\n",
        "        \"other\": \"gray\"\n",
        "    }\n",
        "\n",
        "    for token, true, pred, box in filtered:\n",
        "        if pred == \"O\":\n",
        "            continue\n",
        "        label = iob_to_label(pred)\n",
        "        draw.rectangle(box, outline=label2color.get(label, \"red\"), width=2)\n",
        "        draw.text((box[0] + 5, box[1] - 10), label, fill=label2color.get(label, \"red\"), font=font)\n",
        "\n",
        "    print(\"📷 Modellens prediksjoner:\")\n",
        "    display(image)\n",
        "\n",
        "    # === Fasit (valgfritt)\n",
        "    if show_gt:\n",
        "        gt_img = Image.open(image_path).convert(\"RGB\")\n",
        "        draw_gt = ImageDraw.Draw(gt_img)\n",
        "\n",
        "        for word, box, label_id in zip(words, raw_boxes, string_labels):\n",
        "            if label_id == \"O\":\n",
        "                continue\n",
        "            label_type = iob_to_label(label_id)\n",
        "            draw_gt.rectangle(box, outline=label2color.get(label_type, \"gray\"), width=2)\n",
        "            draw_gt.text((box[0] + 5, box[1] - 10), label_type, fill=label2color.get(label_type, \"gray\"), font=font)\n",
        "\n",
        "        print(\"✅ Ground Truth:\")\n",
        "        display(gt_img)\n",
        "\n",
        "\n",
        "def predict_relations(doc_id):\n",
        "    from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "    base_path = \"/content/drive/MyDrive/DAT255/KVP10k-dataset/kvp10k/test\"\n",
        "    image_path = f\"{base_path}/images/{doc_id}.png\"\n",
        "    ocr_path = f\"{base_path}/ocrs/{doc_id}.json\"\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ocr_data = json.load(f)\n",
        "\n",
        "    page = ocr_data[\"pages\"][0]\n",
        "    words = [w[\"text\"] for w in page[\"words\"]]\n",
        "    raw_boxes = [w[\"bbox\"] for w in page[\"words\"]]\n",
        "    width, height = page[\"width\"], page[\"height\"]\n",
        "    norm_boxes = [normalize_bbox(b, width, height) for b in raw_boxes]\n",
        "\n",
        "    encoding = processor(\n",
        "        image,\n",
        "        words,\n",
        "        boxes=norm_boxes,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"]\n",
        "    bbox = encoding[\"bbox\"]\n",
        "    image_tensor = encoding[\"image\"]\n",
        "    attention_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(\n",
        "            input_ids=input_ids.to(model.device),\n",
        "            bbox=bbox.to(model.device),\n",
        "            image=image_tensor.to(model.device),\n",
        "            attention_mask=attention_mask.to(model.device)\n",
        "        )\n",
        "\n",
        "    # === Extract token predictions and hidden states\n",
        "    logits = output[\"token_logits\"].squeeze()\n",
        "    hidden_states = output[\"hidden_states\"].squeeze()\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # === Identify B-KEY and B-VALUE token indices\n",
        "    keys = []\n",
        "    values = []\n",
        "    for idx, pred in enumerate(predictions.tolist()):\n",
        "        label = id2label.get(pred, \"O\")\n",
        "        if label == \"B-KEY\":\n",
        "            keys.append(idx)\n",
        "        elif label == \"B-VALUE\":\n",
        "            values.append(idx)\n",
        "\n",
        "    # === Predict relations\n",
        "    relations = []\n",
        "    for k in keys:\n",
        "        for v in values:\n",
        "            h_i = hidden_states[k].unsqueeze(0)\n",
        "            h_j = hidden_states[v].unsqueeze(0)\n",
        "            rel_logits = model.relation(h_i, h_j)\n",
        "            pred_rel = torch.argmax(rel_logits, dim=-1).item()\n",
        "            if pred_rel == 1:  # Only keep predicted \"real\" relations\n",
        "                relations.append((k, v))\n",
        "\n",
        "    # === Visualize arrows\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "    for k, v in relations:\n",
        "        key_box = unnormalize_box(bbox[0][k].tolist(), width, height)\n",
        "        val_box = unnormalize_box(bbox[0][v].tolist(), width, height)\n",
        "\n",
        "        # draw arrow line\n",
        "        x0, y0 = (key_box[0] + key_box[2]) / 2, (key_box[1] + key_box[3]) / 2\n",
        "        x1, y1 = (val_box[0] + val_box[2]) / 2, (val_box[1] + val_box[3]) / 2\n",
        "        draw.line([x0, y0, x1, y1], fill=\"red\", width=2)\n",
        "\n",
        "        # draw tokens for context\n",
        "        draw.rectangle(key_box, outline=\"blue\", width=2)\n",
        "        draw.rectangle(val_box, outline=\"green\", width=2)\n",
        "\n",
        "    display(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSekHOh_dR71"
      },
      "source": [
        "#Velg vilkårlig dokument fra datasettet og prediker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QS92Sq_JwuBV"
      },
      "outputs": [],
      "source": [
        "#predict_and_visualize(\"aaf643426f0250efd10de3d9df63b407292f3fcc2aa335e399c37aca32443ea1\")\n",
        "#predict_relations(\"aaf643426f0250efd10de3d9df63b407292f3fcc2aa335e399c37aca32443ea1\")\n",
        "\n",
        "predict_and_visualize(\"aaed61e79aa3edbae844f5775789ebb6aa1a94a23d9cb3468d2cfc974af304e5\")\n",
        "predict_relations(\"aaed61e79aa3edbae844f5775789ebb6aa1a94a23d9cb3468d2cfc974af304e5\")\n",
        "\n",
        "#predict_and_visualize(\"aa35720ba3611f946c372cc99d8cd1d78e81265b8ceb51dcdb4672d196944c2b\")\n",
        "#predict_relations(\"aa35720ba3611f946c372cc99d8cd1d78e81265b8ceb51dcdb4672d196944c2b\")\n",
        "\n",
        "#predict_and_visualize(\"aa7c58830d0e84f98e9fdec1bc9e131227f9b00106aa3c78bc8ea346cfb9eac0\")\n",
        "#predict_relations(\"aa7c58830d0e84f98e9fdec1bc9e131227f9b00106aa3c78bc8ea346cfb9eac0\")\n",
        "\n",
        "#predict_and_visualize(\"faa5d71172e2e9959b41a5aec4fd2ab700534d1b2729484d2d5f26472cd56cfa\")\n",
        "#predict_relations(\"faa5d71172e2e9959b41a5aec4fd2ab700534d1b2729484d2d5f26472cd56cfa\")\n",
        "\n",
        "#predict_and_visualize(\"ffe462e43b9dff12e78ea8fb69332abfb789da171a8597f5bb961853e06e6fa2\")\n",
        "#predict_relations(\"ffe462e43b9dff12e78ea8fb69332abfb789da171a8597f5bb961853e06e6fa2\")\n",
        "\n",
        "#predict_and_visualize(\"feb2c4b21388318c7a51cc0aaf0e7c673a07f5204a40549a281bef065bb77925\")\n",
        "#predict_relations(\"feb2c4b21388318c7a51cc0aaf0e7c673a07f5204a40549a281bef065bb77925\")\n",
        "\n",
        "#predict_and_visualize(\"feaf84d435bd46100db82de51f5a989ff4d39fdcdb040a7044720b943e34b7d7\")\n",
        "#predict_relations(\"feaf84d435bd46100db82de51f5a989ff4d39fdcdb040a7044720b943e34b7d7\")\n",
        "\n",
        "#predict_and_visualize(\"df6b0a4cf1908bb95be874e4efa59411c685095d7bb596879961563503b5c239\")\n",
        "#predict_relations(\"df6b0a4cf1908bb95be874e4efa59411c685095d7bb596879961563503b5c239\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebdfb636"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "from transformers import LayoutLMv3Model\n",
        "\n",
        "class LayoutLMv3WithBinaryRelation(nn.Module):\n",
        "    def __init__(self, model_name=\"microsoft/layoutlmv3-base\", hidden_size=768):\n",
        "        super().__init__()\n",
        "        self.layoutlmv3 = LayoutLMv3Model.from_pretrained(model_name)\n",
        "        self.relation_classifier = nn.Bilinear(hidden_size, hidden_size, 1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, bbox, attention_mask, entity_pairs):\n",
        "        outputs = self.layoutlmv3(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "\n",
        "        batch_relations = []\n",
        "        for batch_idx, pairs in enumerate(entity_pairs):\n",
        "            head_tail_preds = []\n",
        "            for (head_idxs, tail_idxs) in pairs:\n",
        "                head_repr = sequence_output[batch_idx, head_idxs].mean(dim=0)\n",
        "                tail_repr = sequence_output[batch_idx, tail_idxs].mean(dim=0)\n",
        "\n",
        "                rel_logit = self.relation_classifier(self.dropout(head_repr), self.dropout(tail_repr))\n",
        "                rel_prob = self.sigmoid(rel_logit).squeeze()\n",
        "                head_tail_preds.append(rel_prob)\n",
        "            batch_relations.append(torch.stack(head_tail_preds))\n",
        "        return batch_relations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee3f72fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example usage after BIO tagging to get entity pairs:\n",
        "# entity_pairs = [[([start1, start1+1], [start2]), ([start3], [start4, start4+1])], ...]\n",
        "# This should be constructed based on decoded BIO tag spans\n",
        "\n",
        "model = LayoutLMv3WithBinaryRelation()\n",
        "model.eval()\n",
        "\n",
        "# Dummy input\n",
        "batch_size, seq_len = 2, 512\n",
        "input_ids = torch.randint(0, 1000, (batch_size, seq_len))\n",
        "bbox = torch.randint(0, 1000, (batch_size, seq_len, 4))\n",
        "attention_mask = torch.ones((batch_size, seq_len), dtype=torch.long)\n",
        "\n",
        "entity_pairs = [\n",
        "    [([10, 11], [15]), ([20], [30, 31])],\n",
        "    [([5], [6]), ([100], [101])]\n",
        "]\n",
        "\n",
        "with torch.no_grad():\n",
        "    relation_probs = model(input_ids, bbox, attention_mask, entity_pairs)\n",
        "\n",
        "for i, probs in enumerate(relation_probs):\n",
        "    print(f\"Batch {i}: {[float(p) for p in probs]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08ca1e6e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ─────────────── Innlasting av RE‑dataset ───────────────\n",
        "from datasets import load_from_disk\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Last inn train og test\n",
        "train_hf = load_from_disk(\"/content/drive/MyDrive/RE_ready/re_dataset_train_combined\")\n",
        "test_hf  = load_from_disk(\"/content/drive/MyDrive/RE_ready/re_dataset_test_combined\")\n",
        "\n",
        "class REPartnerDataset(Dataset):\n",
        "    def __init__(self, hf_dataset):\n",
        "        self.ds = hf_dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.ds[idx]\n",
        "        hi    = torch.tensor(ex[\"h_i\"],    dtype=torch.float)\n",
        "        hj    = torch.tensor(ex[\"h_j\"],    dtype=torch.float)\n",
        "        himul = torch.tensor(ex[\"h_mul\"],  dtype=torch.float)\n",
        "        hidiff= torch.tensor(ex[\"h_diff\"], dtype=torch.float)\n",
        "        hdot  = torch.tensor([ex[\"h_dot\"]], dtype=torch.float)\n",
        "        label = torch.tensor(ex[\"label\"],   dtype=torch.float)\n",
        "        return hi, hj, himul, hidiff, hdot, label\n",
        "\n",
        "train_ds = REPartnerDataset(train_hf)\n",
        "test_ds  = REPartnerDataset(test_hf)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f813199"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ─────────────── Klassifikator ───────────────\n",
        "import torch.nn as nn\n",
        "\n",
        "class RelationClassifier(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(4 * hidden_dim + 1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, hi, hj, himul, hidiff, hdot):\n",
        "        x = torch.cat([hi, hj, himul, hidiff, hdot], dim=-1)\n",
        "        return self.fc(x).squeeze(-1)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "hidden_dim = len(train_hf[0][\"h_i\"])\n",
        "model = RelationClassifier(hidden_dim).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3807fc9a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ─────────────── Trenings‑loop ───────────────\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for hi, hj, himul, hidiff, hdot, label in train_loader:\n",
        "        hi, hj, himul, hidiff, hdot, label = [t.to(device) for t in (hi, hj, himul, hidiff, hdot, label)]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(hi, hj, himul, hidiff, hdot)\n",
        "        loss = criterion(logits, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * hi.size(0)\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} — loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89e5344e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ─────────────── Evaluerings‑loop ───────────────\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for hi, hj, himul, hidiff, hdot, label in test_loader:\n",
        "        hi, hj, himul, hidiff, hdot = [t.to(device) for t in (hi, hj, himul, hidiff, hdot)]\n",
        "        logits = model(hi, hj, himul, hidiff, hdot)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()\n",
        "        all_preds.extend(probs)\n",
        "        all_labels.extend(label.numpy())\n",
        "\n",
        "bin_preds = [1 if p >= 0.5 else 0 for p in all_preds]\n",
        "\n",
        "acc = accuracy_score(all_labels, bin_preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, bin_preds, average=\"binary\")\n",
        "\n",
        "print(\"\\n=== Evalueringsresultater ===\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e38f72f7d0940d39302cdc1065bc6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cf0641365cd44a8aa8442b9f96f0e86",
              "IPY_MODEL_2e3d589b62ea42069995d48ce568ba08",
              "IPY_MODEL_7b214af6b9e44c278ffb65f22e4aab2b"
            ],
            "layout": "IPY_MODEL_6030dd5cdd2947509bcebc9c37f5102a"
          }
        },
        "9cf0641365cd44a8aa8442b9f96f0e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029637c1faf84f25bf2a72ba7394c023",
            "placeholder": "​",
            "style": "IPY_MODEL_ce215149d3184b438bbe08ff4da3238b",
            "value": "Map: 100%"
          }
        },
        "2e3d589b62ea42069995d48ce568ba08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae183f5cafb2471ab6f6d89671a3ee96",
            "max": 6273,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9047638760d04fccacf29ea5f07609e1",
            "value": 6273
          }
        },
        "7b214af6b9e44c278ffb65f22e4aab2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cd980b7da6649ac9c6beb5402e30462",
            "placeholder": "​",
            "style": "IPY_MODEL_d998de5c800c4212b8b5bcc30332836f",
            "value": " 6273/6273 [02:52&lt;00:00, 49.56 examples/s]"
          }
        },
        "6030dd5cdd2947509bcebc9c37f5102a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029637c1faf84f25bf2a72ba7394c023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce215149d3184b438bbe08ff4da3238b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae183f5cafb2471ab6f6d89671a3ee96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9047638760d04fccacf29ea5f07609e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cd980b7da6649ac9c6beb5402e30462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d998de5c800c4212b8b5bcc30332836f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5df32418f5894b3384c85664d14b3bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b336fb536dc14ba3a508e19b3f6e55f3",
              "IPY_MODEL_6b63067af4f74d3f9b7417e8e3dbb58e",
              "IPY_MODEL_f09e0705ed21489e9644ab24620da3b1"
            ],
            "layout": "IPY_MODEL_fb3ee83578c1482488b61d631a7a861f"
          }
        },
        "b336fb536dc14ba3a508e19b3f6e55f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25e8c49ea8d1493bbd7cc221dfc50c10",
            "placeholder": "​",
            "style": "IPY_MODEL_044dce4c059647819efb02d254d2fc19",
            "value": "Map: 100%"
          }
        },
        "6b63067af4f74d3f9b7417e8e3dbb58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ddffde07214109ac7f9ed95f593046",
            "max": 1569,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bc284696be54b70bc63a8047467484f",
            "value": 1569
          }
        },
        "f09e0705ed21489e9644ab24620da3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4f00e13c0e41aea4b7dbdd6b4f6d19",
            "placeholder": "​",
            "style": "IPY_MODEL_ca3155b4efef4f4a9867217c857cebc1",
            "value": " 1569/1569 [00:43&lt;00:00, 48.54 examples/s]"
          }
        },
        "fb3ee83578c1482488b61d631a7a861f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e8c49ea8d1493bbd7cc221dfc50c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044dce4c059647819efb02d254d2fc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6ddffde07214109ac7f9ed95f593046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc284696be54b70bc63a8047467484f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea4f00e13c0e41aea4b7dbdd6b4f6d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3155b4efef4f4a9867217c857cebc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57030de9dd074234a1a3d4d94fc5ae81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_216496bf28b0438e80fdbc2f5d4a5bb3",
              "IPY_MODEL_30b38db6d9ca4dc786d82f85aa4692b9",
              "IPY_MODEL_90279cc68ace4c77838dd9bfa6c7797b"
            ],
            "layout": "IPY_MODEL_54f86307e15a482ab8be56db4f56dd71"
          }
        },
        "216496bf28b0438e80fdbc2f5d4a5bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc506c74694d490ca8dfa8b6b53f62d2",
            "placeholder": "​",
            "style": "IPY_MODEL_c6a9cc8d8c3142b3ab7fdc3166a55556",
            "value": "Map: 100%"
          }
        },
        "30b38db6d9ca4dc786d82f85aa4692b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_014fefe32b524a009a54852170ef464e",
            "max": 828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e37d1b3f14204b47a7405dc92aafb035",
            "value": 828
          }
        },
        "90279cc68ace4c77838dd9bfa6c7797b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a07d334961462a9d607819488499cf",
            "placeholder": "​",
            "style": "IPY_MODEL_eb87865008e143e5aa593482b699ba81",
            "value": " 828/828 [00:23&lt;00:00, 48.50 examples/s]"
          }
        },
        "54f86307e15a482ab8be56db4f56dd71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc506c74694d490ca8dfa8b6b53f62d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a9cc8d8c3142b3ab7fdc3166a55556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "014fefe32b524a009a54852170ef464e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37d1b3f14204b47a7405dc92aafb035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67a07d334961462a9d607819488499cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb87865008e143e5aa593482b699ba81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}