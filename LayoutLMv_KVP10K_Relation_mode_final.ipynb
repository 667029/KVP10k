{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VofLEluS_HIY"
      },
      "source": [
        "#Dokumentforståelse med LayoutLMv3 på KVP10k-datasettet\n",
        "\n",
        "Denne notebooken demonstrerer hvordan vi henter inn en preprossessert og tilpasset versjon av KVP10k-datasettet i Hugging Face-format, til å utføre **Key-Value Pair Extraction (KVP)** på  dokumentbilder.\n",
        "\n",
        "- Datasettet består av over 10k forretningsdokumenter, og inneholder blant annet dokumentbilder og tilhørende nøkkel-verdi-par, som brukes av denne fine-tuned modellen som utvikles her.\n",
        "\n",
        "- Sluttmålet er å utvikle og trene en ny modell til dokumentforståelse, ved å forstå **visuell layout**, **tekstlig innhold**, og **relasjoner mellom nøkler og verdier** i dokumentene.\n",
        "  - KVP-Extraction modellen som utvikles i denne notebooken er tenkt å brukes grunnmur i sluttmodellen, for å med stor sannsynlighet beherske å linke mellom nøkkel-verdi-par i ulike dokumenter.\n",
        "\n",
        "LayoutLMv3 er en multi-modal modell designet for å kombinere tekst, layout og annen bilde-informasjon\n",
        "\n",
        "---\n",
        "\n",
        "###**Notbooken dekker følgende steg**:\n",
        "\n",
        "1. Installasjon av de nødendige biblioteker\n",
        "2. Lasting av forhåndsprosessert datasett\n",
        "3. Tokenisering av tekst og input-formatering med Layout sin Processor\n",
        "- 3.1 Logikk for å anngi predikerte BIO-labels til dokumentets bbox'es\n",
        "4. Trening av modell for token-klassifisering\n",
        "5. Evaluering og lagring av modell i Drive\n",
        "6. Visualisering av modell under inferense\n",
        "\n",
        "---\n",
        "\n",
        "###**LayoutLMv3Processor - gjør følgende**:\n",
        "1. Tekst-tokenisering: Tekst fra dokumentet tokeniseres.\n",
        "2. Token-connection: Hvert token kobles til en bounding box (bbox) på dokumentet, gjennom *boxes*-parmeteret som inneholder (x0,y0,x1,y1)-kordinater til hvert token.\n",
        "3. Image-embedding: Dokumentbildet skaleres og legges og blir input til modellen\n",
        "4. Label-alignment: Hvert token får en BIO-label, som brukes under modellens token-klassifisering\n",
        "\n",
        "Tokeniseringen handler om å forvandle dokumentet til tokens med alle nødvendige modaliteter (tekst, layout og bilde) slik at modellen lærer sammenhengen mellom dem gjennom trening.\n",
        "\n",
        "**Det brukes BIO-tagger, og dette er hva det står for:**\n",
        " - B --> Begin: første token i en entitet.\n",
        " - I --> Inside: inne i en entitet.\n",
        " - O --> Outside: tokenen er ikke en del av noen entitet\n",
        "\n",
        "f.eks.\n",
        "  - Tokens:  [\"Name\", \"of\", \"buyer\", \":\", \"Ole\", \"Martin\", \"Lystadmoen\"]\n",
        "  - Labels:  [\"B-KEY\", \"I-KEY\", \"I-KEY\", \"O\", \"B-VALUE\", \"I-VALUE\", \"I-VALUE\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "caef954e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0NSOqNmukkk"
      },
      "source": [
        "# Dataset - forståelse\n",
        "\n",
        "**Innhold i train/-mappen i KVP10k:**\n",
        "_____\n",
        "  - *images*/ --> .png bilder av hvert dokument. Visuell input for modellen.\n",
        "    - Det modellen \"ser\".\n",
        "_____\n",
        "\n",
        "  - *ocrs*/ --> JSON-filer med **words** og **bboxes** for hvert dokument. Gir tekst og posisjoner fra OCR, og brukes sammen med images.\n",
        "    - Det modellen \"leser\" (tokens og posisjonene deres).\n",
        "\n",
        "_____\n",
        "\n",
        "  - *gts*/ --> JSON-filer med KVPs og tilhørende bboxes. Inneholder hvilke keys og values som hører sammen.\n",
        "    - Det som lærer modellen hvilke tokens som er nøkler, verdier, og hvilket som er koblet sammen.\n",
        "_____\n",
        "\n",
        "  - *items*/ --> JSON-filer med annotasjoner og layout-objs (rektangler, linker, etiketter)\n",
        "    - tilleggsinformasjon\n",
        "    - ikke viktig i for EE\n",
        "    - Helt nødvendig i RE-delen av dette prosjektet\n",
        "_____"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "TqejcrWXvnoL"
      },
      "outputs": [],
      "source": [
        "#transformers: Hugging Face bibliotek som gir tilgang til LayoutLMv3\n",
        "#datasets: For håndtering av dataset i Huggig Face-format\n",
        "#seqeval: evalueringsbibliotek for sekvensmerking, brukes for måle metrikker for i dette tilfelle BIO-tagging\n",
        "!pip install -q -U transformers datasets seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Av-n3h6jaou3"
      },
      "outputs": [],
      "source": [
        "#Håndterer ulike metrikker inkl. integrasjon med seqeval\n",
        "!pip install -q evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GE27SIYc2Y2y"
      },
      "outputs": [],
      "source": [
        "import os              #navigere mapper og filer, hente filbaner\n",
        "from PIL import Image  #åpne, vise og manipulere bilder\n",
        "import json            #lese/skrive til JSON-filer\n",
        "from transformers import LayoutLMv3Processor\n",
        "import torch           #modellens input-format for data\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Uup0eV5_usd",
        "outputId": "600e93cd-d9e2-4d1f-e098-c801d9a39dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WmYZ6LnbaWTv"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "metric = load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW4eqj9o2trD",
        "outputId": "1585b317-28a2-4750-e627-c287bc4f56c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train', 'test']\n"
          ]
        }
      ],
      "source": [
        "base_path = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/\"\n",
        "print(os.listdir(base_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WYm7ncZw_lSW"
      },
      "outputs": [],
      "source": [
        "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False) # <-- Viktig fordi vi allerede har utført OCR på bildet og har tekst og bboxes\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RsRz3cC2_8mj"
      },
      "outputs": [],
      "source": [
        "# Mapping fra tekstlige BIO-labels til tall som modellen bruker\n",
        "label_map = {\n",
        "    \"O\": 0,\n",
        "    \"B-KEY\": 1,\n",
        "    \"I-KEY\": 2,\n",
        "    \"B-VALUE\": 3,\n",
        "    \"I-VALUE\": 4,\n",
        "}\n",
        "\n",
        "# Funksjon for å skalere bounding boxes til 0-1000 (som LayoutLMv3 krever)\n",
        "def normalize_bbox(bbox, width, height):\n",
        "  return [\n",
        "      int(1000 * (bbox[0] /width)),\n",
        "      int(1000 * (bbox[1] / height)),\n",
        "      int(1000 * (bbox[2] / width)),\n",
        "      int(1000 * (bbox[3] / height))\n",
        "  ]\n",
        "\n",
        "\n",
        "def assign_label_for_box(box, boxes, label_type):\n",
        "  \"\"\"Returnerer liste med (index, label) for tokens som overlapper box\"\"\"\n",
        "  overlaps = []\n",
        "  for i, token_box in enumerate(boxes):\n",
        "    if box_overlap(box, token_box) > 0:\n",
        "      overlaps.append(i)\n",
        "\n",
        "  overlaps = sorted(overlaps)\n",
        "\n",
        "  labeled = []\n",
        "  for j, idx in enumerate(overlaps):\n",
        "    tag = f\"B-{label_type}\" if j == 0 else f\"I-{label_type}\"\n",
        "    labeled.append((idx, tag))\n",
        "\n",
        "  return labeled\n",
        "\n",
        "\n",
        "#Sjekker om OCR-boksen overlapper med GTS(key/value)-boksen.\n",
        "#Ved overlapp hører de til hverandre.\n",
        "def box_overlap(box1, box2):\n",
        "  x0 = max(box1[0], box2[0])\n",
        "  y0 = max(box1[1], box2[1])\n",
        "  x1 = min(box1[2], box2[2])\n",
        "  y1 = min(box1[3], box2[3])\n",
        "  return max(0, x1 - x0) * max(0, y1 - y0)\n",
        "\n",
        "\n",
        "# Funksjon for å generere BIO-labels fra gts (ground truth).\n",
        "# Lager en BIO-label for hvert token basert på om det overlapper med en key- eller value-boks fra GTS.\n",
        "# Matcher hvert token fra OCR (word + bbox) mot key/value-bbokser fra gts:\n",
        "# --> Token overlapper en nøkkelboks: B-KEY eller I-KEY\n",
        "# --> Token overlapper en verdiboks: B-VALUE eller I-VALUE\n",
        "# --> Ellers: O\n",
        "def iob_from_kvps(words, boxes, kvps):\n",
        "  labels = [\"O\"] * len(words)\n",
        "\n",
        "  #Gå igjennom alle key-value-pairs\n",
        "  for kvp in kvps:\n",
        "    if \"key\" in kvp and \"bbox\" in kvp[\"key\"]:\n",
        "      key_bbox = kvp[\"key\"][\"bbox\"]\n",
        "      for idx, tag in assign_label_for_box(key_bbox, boxes, \"KEY\"):\n",
        "        labels[idx] = tag\n",
        "\n",
        "    if \"value\" in kvp and \"bbox\" in kvp[\"value\"]:\n",
        "      value_box = kvp[\"value\"][\"bbox\"]\n",
        "      for idx, tag in assign_label_for_box(value_box, boxes, \"VALUE\"):\n",
        "        labels[idx] = tag\n",
        "\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94wyjeWiRmJG",
        "outputId": "b5ac79e3-4ecf-4a67-c737-348171680b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: /content/drive/MyDrive/KVP10k_processed_ready: No such file or directory\n",
            "lrw------- 1 root root 0 Apr 21 09:10 /content/drive/MyDrive/KVP10k_processed_ready -> /content/drive/.shortcut-targets-by-id/1NbM9cwuCpZGK4W3yzn5hIDmqyp3uULqw/KVP10k_processed_ready\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content/drive/MyDrive/KVP10k_processed_ready\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl8UG_z9fMpK"
      },
      "source": [
        "#Innlasting av et allerede pre-prossesert KVP10k-dataset spesielt utviklet for LayoutLMv3 (KVP-extraction).\n",
        "\n",
        "\n",
        "Henter allerede preprosserert dataset for layout modellen og legger til entiteter og labels for relasjonslaget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrLS234HQhcG",
        "outputId": "a7b001d1-250e-44a5-a8ab-e50281544ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from datasets import load_from_disk\n",
        "\n",
        "# Monter Drive (hvis du ikke har gjort det)\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Last inn dataset fra riktig path\n",
        "dataset = load_from_disk(\"/content/drive/MyDrive/KVP10k_processed_ready/dataset_all_gts\")\n",
        "\n",
        "# Hent splits\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"eval\"]\n",
        "test_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187,
          "referenced_widgets": [
            "50976af228364669b660c60d6912d79d",
            "c91273fb1b814c86a2516611a8138b33",
            "b1c9dcf8fc754d5eb7a5b8298f9568cf",
            "7fecc948801345c4baa7979cdb8a3e2f",
            "e16b732e548146908e9beaf30cf44450",
            "eda1823c3ed647568dd7a024f87186c7",
            "b20e9d7517324e88a88985e21716afeb",
            "638f0b0bee94429cbff75fc4877c1023",
            "691190f7ad87413983d1117d99462334",
            "9a82fcdab4764a039d0645663cce00eb",
            "4c8629355e114774bda009ffc5a22040",
            "6b6ebc0406c14f1eaf252ae0fb1f2ee2",
            "c1b370c17ae346a290494bb219fef36d",
            "eed947af794944729c200c17710d144d",
            "a4467d115ad4409e9af2ec26666a8dbf",
            "85c4547dbc6042eda9134c8ece77e34e",
            "a0cab32a45b542c59277ad00facf8ed2",
            "026ab7fe2a7f45e48fc33c43b6328237",
            "fb10feafc8b545a0875315f9da4978e0",
            "69a336e859c14418a72a8a20ca8d9051",
            "8882e58ddd194a0e884dd9011cf264a6",
            "bf4be281d7b644e0acecf622ffca354e",
            "9770f8e4be364e208355c6c034d5258c",
            "b980227ae8f94e279164b95d94407c4e",
            "89a9c1f5564947c094af587faa89cd55",
            "3a9703984c514ddbafe99e03ba289383",
            "17e44e97deec42d5a528b374cb9f4e8d",
            "429b8ba614794f148f1cc65c4e7f6cfc",
            "44e2e6b0d58e43c2ae2349098c9dd41c",
            "53bb0e95769d41359268603e1b12bdd0",
            "0659cf55ff534bfeb5078a0c563b1aeb",
            "326667ef8b724c81a124499b1e2712b1",
            "0f9ca318b71d429d9190f10ebff7f369"
          ]
        },
        "id": "IEkZt_FZWeuV",
        "outputId": "a5db5bf1-58b2-4eda-c4e2-656ff5aeb26b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6273 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50976af228364669b660c60d6912d79d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1569 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b6ebc0406c14f1eaf252ae0fb1f2ee2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/828 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9770f8e4be364e208355c6c034d5258c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 6273\n",
            "Eval: 1569\n",
            "Test: 828\n",
            "Keys: dict_keys(['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'entity_pairs', 'rel_labels'])\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def add_entity_pairs_and_labels(example, neg_per_pos: int = 3):\n",
        "    # Hent ut token-labels\n",
        "    labels   = example[\"labels\"]\n",
        "    id2label = {0: \"O\", 1: \"B-KEY\", 2: \"I-KEY\", 3: \"B-VALUE\", 4: \"I-VALUE\"}\n",
        "\n",
        "    # Finn KEY- og VALUE-spans\n",
        "    key_spans, value_spans = [], []\n",
        "    cur_span, cur_type = [], None\n",
        "    for i, lab in enumerate(labels):\n",
        "        if lab == -100:\n",
        "            continue\n",
        "        lbl = id2label[int(lab)]\n",
        "        if lbl.startswith(\"B-\"):\n",
        "            # lagre forrige span\n",
        "            if cur_span:\n",
        "                (key_spans if cur_type==\"KEY\" else value_spans).append(cur_span)\n",
        "            cur_span = [i]\n",
        "            cur_type = lbl.split(\"-\",1)[1]\n",
        "        elif lbl.startswith(\"I-\") and cur_type and lbl.endswith(cur_type):\n",
        "            cur_span.append(i)\n",
        "        else:\n",
        "            if cur_span:\n",
        "                (key_spans if cur_type==\"KEY\" else value_spans).append(cur_span)\n",
        "            cur_span, cur_type = [], None\n",
        "    if cur_span:\n",
        "        (key_spans if cur_type==\"KEY\" else value_spans).append(cur_span)\n",
        "\n",
        "    # Lag positive par\n",
        "    pos_pairs  = [(k, v) for k, v in zip(key_spans, value_spans)]\n",
        "    pos_labels = [1.0] * len(pos_pairs)\n",
        "\n",
        "    # Lag negative par\n",
        "    neg_pairs, neg_labels = [], []\n",
        "    if key_spans and value_spans:\n",
        "        for k in key_spans:\n",
        "            # kandidater som ikke er ekte par\n",
        "            cands = [v for v in value_spans if (k,v) not in pos_pairs]\n",
        "            for v in random.sample(cands, min(len(cands), neg_per_pos)):\n",
        "                neg_pairs.append((k, v))\n",
        "                neg_labels.append(0.0)\n",
        "\n",
        "    # Fallback om ingen par\n",
        "    if not pos_pairs:\n",
        "        pos_pairs, pos_labels = [([0],[1])], [0.0]\n",
        "\n",
        "    # Kombiner og tilordne\n",
        "    example[\"entity_pairs\"] = pos_pairs + neg_pairs\n",
        "    example[\"rel_labels\"]    = pos_labels + neg_labels\n",
        "    return example\n",
        "\n",
        "# Apply to your datasets:\n",
        "train_dataset = train_dataset.map(lambda ex: add_entity_pairs_and_labels(ex, neg_per_pos=3))\n",
        "eval_dataset  = eval_dataset.map(lambda ex: add_entity_pairs_and_labels(ex, neg_per_pos=1))\n",
        "test_dataset  = test_dataset.map(lambda ex: add_entity_pairs_and_labels(ex, neg_per_pos=1))\n",
        "\n",
        "# And then:\n",
        "train_dataset.set_format(\"torch\")\n",
        "eval_dataset.set_format(\"torch\")\n",
        "test_dataset.set_format(\"torch\")\n",
        "\n",
        "\n",
        "# Sjekk at alt fungerer\n",
        "print(\"Train:\", len(train_dataset))\n",
        "print(\"Eval:\", len(eval_dataset))\n",
        "print(\"Test:\", len(test_dataset))\n",
        "print(\"Keys:\", train_dataset[0].keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya332BhmGLt_",
        "outputId": "20d13043-2225-4dfc-dd8a-49ce310615a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': Array3D(shape=(3, 224, 224), dtype='float32', id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              " 'bbox': Array2D(shape=(512, 4), dtype='int64', id=None),\n",
              " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              " 'entity_pairs': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),\n",
              " 'rel_labels': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_dataset.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EB3kZmZpTu-m",
        "outputId": "e5ae047d-a5f5-4651-fcb4-bfe04250399b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel_values torch.Size([3, 224, 224])\n",
            "input_ids torch.Size([512])\n",
            "attention_mask torch.Size([512])\n",
            "bbox torch.Size([512, 4])\n",
            "labels torch.Size([512])\n",
            "entity_pairs torch.Size([1, 2, 1])\n",
            "rel_labels torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "example = train_dataset[0]\n",
        "for k,v in example.items():\n",
        "    print(k,v.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "collapsed": true,
        "id": "GTN1cXBYTynu",
        "outputId": "6c21bc54-61eb-4392-e990-7d61ae139d58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Date Net Zone/Syscode Time Spot Name Len Line Rate Flag 10-722 HIST L Middlesx Smrst Cty Zone 1302/1302 4:44PM CLFTVNJO702H 30 48 $73.00 10-722 HIST L Middlesx Smrst Cty Zone 1302/1302 7:45PM CLFTVNJO702H 30 487 $90.00 10-722 HIST L Middlesx Smrst Cty Zone 1302/1302 11:46PM CLFTVNJO702H 30 487 $90.00 10-722 AEN Morris County Zone 1305/1305 2:13PM CLFTVNJO702H 30 488 $21.00 10-722 AEN Morris County Zone 1305/1305 5:40PM CLFTVNJO702H 30 489 $49.00 10-722 AEN Morris County Zone 1305/1305 7:44PM CLFTVNJO702H 30 490 $59.00 10-722 AEN Morris County Zone 1305/1305 10:48PM CLFTVNJO702H 30 490 $59.00 10-722 CNN Morris County Zone 1305/1305 8:29AM CLFTVNJO702H 30 491 $73.00 10-722 CNN Morris County Zone 1305/1305 3:30PM CLFTVNJO702H 30 492 $65.00 10-722 CNN Morris County Zone 1305/1305 4:26PM CLFTVNJO702H 30 493 $121.00 10-722 CNN Morris County Zone 1305/1305 9:27PM CLFTVNJO702H 30 494 $164.00 10-722 DISC Morris County Zone 1305/1305 9:25AM CLFTVNJO702H 30 495 $21.00 10-722 DISC Morris County Zone 1305/1305 6:41PM CLFTVNJO702H 30 496 $49.00 10-722 DISC Morris County Zone 1305/1305 9:42PM CLFTVNJO702H 30 497 $59.00 10-722 DISC Morris County Zone 1305/1305 11:49PM CLFTVNJO702H 30 497 $59.00 10-722 FXNC</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "processor.tokenizer.decode(train_dataset[0][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hhU1sClvWGOS",
        "outputId": "0bf43eb4-c66f-486b-fdbd-73a4eab5fbab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> -100\n",
            " Date 0\n",
            " Net 0\n",
            " Zone 0\n",
            "/ -100\n",
            "Sys -100\n",
            "code -100\n",
            " Time 0\n",
            " Spot 0\n",
            " Name 0\n",
            " Len 0\n",
            " Line 0\n",
            " Rate 0\n",
            " Flag 0\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " H 0\n",
            "IST -100\n",
            " L 0\n",
            " Middles 0\n",
            "x -100\n",
            " Sm 0\n",
            "r -100\n",
            "st -100\n",
            " C 0\n",
            "ty -100\n",
            " Zone 0\n",
            " 130 0\n",
            "2 -100\n",
            "/ -100\n",
            "130 -100\n",
            "2 -100\n",
            " 4 0\n",
            ": -100\n",
            "44 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 48 0\n",
            " $ 0\n",
            "73 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " H 0\n",
            "IST -100\n",
            " L 0\n",
            " Middles 0\n",
            "x -100\n",
            " Sm 0\n",
            "r -100\n",
            "st -100\n",
            " C 0\n",
            "ty -100\n",
            " Zone 0\n",
            " 130 0\n",
            "2 -100\n",
            "/ -100\n",
            "130 -100\n",
            "2 -100\n",
            " 7 0\n",
            ": -100\n",
            "45 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 48 0\n",
            "7 -100\n",
            " $ 0\n",
            "90 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " H 0\n",
            "IST -100\n",
            " L 0\n",
            " Middles 0\n",
            "x -100\n",
            " Sm 0\n",
            "r -100\n",
            "st -100\n",
            " C 0\n",
            "ty -100\n",
            " Zone 0\n",
            " 130 0\n",
            "2 -100\n",
            "/ -100\n",
            "130 -100\n",
            "2 -100\n",
            " 11 0\n",
            ": -100\n",
            "46 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 48 0\n",
            "7 -100\n",
            " $ 0\n",
            "90 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " A 0\n",
            "EN -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 2 0\n",
            ": -100\n",
            "13 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 4 0\n",
            "88 -100\n",
            " $ 0\n",
            "21 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " A 0\n",
            "EN -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 5 0\n",
            ": -100\n",
            "40 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 4 0\n",
            "89 -100\n",
            " $ 0\n",
            "49 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " A 0\n",
            "EN -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 7 0\n",
            ": -100\n",
            "44 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 490 0\n",
            " $ 0\n",
            "59 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " A 0\n",
            "EN -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 10 0\n",
            ": -100\n",
            "48 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 490 0\n",
            " $ 0\n",
            "59 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " CNN 0\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 8 0\n",
            ": -100\n",
            "29 -100\n",
            "AM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "1 -100\n",
            " $ 0\n",
            "73 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " CNN 0\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 3 0\n",
            ": -100\n",
            "30 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "2 -100\n",
            " $ 0\n",
            "65 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " CNN 0\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 4 0\n",
            ": -100\n",
            "26 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "3 -100\n",
            " $ 0\n",
            "121 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " CNN 0\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 9 0\n",
            ": -100\n",
            "27 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "4 -100\n",
            " $ 0\n",
            "164 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " DIS 0\n",
            "C -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 9 0\n",
            ": -100\n",
            "25 -100\n",
            "AM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 4 0\n",
            "95 -100\n",
            " $ 0\n",
            "21 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " DIS 0\n",
            "C -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 6 0\n",
            ": -100\n",
            "41 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 4 0\n",
            "96 -100\n",
            " $ 0\n",
            "49 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " DIS 0\n",
            "C -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 9 0\n",
            ": -100\n",
            "42 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "7 -100\n",
            " $ 0\n",
            "59 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " DIS 0\n",
            "C -100\n",
            " Morris 0\n",
            " County 0\n",
            " Zone 0\n",
            " 130 0\n",
            "5 -100\n",
            "/ -100\n",
            "130 -100\n",
            "5 -100\n",
            " 11 0\n",
            ": -100\n",
            "49 -100\n",
            "PM -100\n",
            " CL 0\n",
            "F -100\n",
            "TV -100\n",
            "NJ -100\n",
            "O -100\n",
            "702 -100\n",
            "H -100\n",
            " 30 0\n",
            " 49 0\n",
            "7 -100\n",
            " $ 0\n",
            "59 -100\n",
            ". -100\n",
            "00 -100\n",
            " 10 0\n",
            "- -100\n",
            "7 -100\n",
            "22 -100\n",
            " FX 0\n",
            "NC -100\n",
            "</s> -100\n"
          ]
        }
      ],
      "source": [
        "for id, label in zip(train_dataset[0][\"input_ids\"], train_dataset[0][\"labels\"]):\n",
        "  print(processor.tokenizer.decode([id]), label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "85WPa0CnB9oT"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    out = {}\n",
        "    # Stack standard tensors\n",
        "    for k in (\"input_ids\", \"bbox\", \"attention_mask\", \"labels\", \"image\"):\n",
        "        if k in batch[0]:\n",
        "            out[k] = torch.stack([b[k] for b in batch])\n",
        "\n",
        "    # Pad and stack rel_labels\n",
        "    max_rel = max(len(b[\"rel_labels\"]) for b in batch)\n",
        "    rels = []\n",
        "    for b in batch:\n",
        "        lab = b[\"rel_labels\"]\n",
        "        lab = lab.tolist() if isinstance(lab, torch.Tensor) else lab\n",
        "        pad = lab + [0.0] * (max_rel - len(lab))\n",
        "        rels.append(torch.tensor(pad, dtype=torch.float))\n",
        "    out[\"rel_labels\"] = torch.stack(rels)\n",
        "\n",
        "    # Collect entity_pairs directly\n",
        "    out[\"entity_pairs\"] = [b[\"entity_pairs\"] for b in batch]\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9JeBWEZzCFKj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "eval_loader  = DataLoader(eval_dataset,  batch_size=8, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VEVsZw_vDaHL"
      },
      "outputs": [],
      "source": [
        "label_list = [\"O\", \"B-KEY\", \"I-KEY\", \"B-VALUE\", \"I-VALUE\"]\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrotUlpib9Mh"
      },
      "source": [
        "#Oppsett av Utvidet Layoutmvl3 model med et relasjons lag\n",
        "Vi setter opp en base model som med et binært relasjonslag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiG8y0XzqShC"
      },
      "source": [
        "##Setter opp metode for rekne ut metrikker for treningen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0nAjhdhwa1fh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "\n",
        "    # === Token classification metrics (BIO tagging) – unchanged\n",
        "    token_preds = predictions[\"token_logits\"]\n",
        "    token_labels = labels[\"labels\"]\n",
        "\n",
        "    token_preds = np.argmax(token_preds, axis=2)\n",
        "    true_preds = [\n",
        "        [id2label[p] for (p, l) in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(token_preds, token_labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(token_preds, token_labels)\n",
        "    ]\n",
        "\n",
        "    bio_result = metric.compute(predictions=true_preds, references=true_labels)\n",
        "\n",
        "    # === Relation classification metrics (per‐pair binary) ===\n",
        "    rel_logits = predictions[\"rel_logits\"]    # shape (batch_size, max_pairs)\n",
        "    rel_labels = labels[\"rel_labels\"]         # same shape\n",
        "\n",
        "    if rel_logits is not None and rel_labels is not None:\n",
        "        # sigmoid → threshold → flatten\n",
        "        rel_probs      = 1 / (1 + np.exp(-rel_logits))\n",
        "        rel_preds_bin  = (rel_probs >= 0.5).astype(int).ravel()\n",
        "        rel_labels_flat= np.array(rel_labels, dtype=int).ravel()\n",
        "\n",
        "        rel_acc       = accuracy_score(rel_labels_flat, rel_preds_bin)\n",
        "        rel_f1        = f1_score(rel_labels_flat, rel_preds_bin, average=\"macro\")\n",
        "        rel_precision = precision_score(rel_labels_flat, rel_preds_bin, average=\"macro\")\n",
        "        rel_recall    = recall_score(rel_labels_flat, rel_preds_bin, average=\"macro\")\n",
        "    else:\n",
        "        rel_acc = rel_f1 = rel_precision = rel_recall = 0.0\n",
        "\n",
        "    return {\n",
        "        # BIO tagging\n",
        "        \"precision\": bio_result[\"overall_precision\"],\n",
        "        \"recall\":    bio_result[\"overall_recall\"],\n",
        "        \"f1\":        bio_result[\"overall_f1\"],\n",
        "        \"accuracy\":  bio_result[\"overall_accuracy\"],\n",
        "\n",
        "        # Relation prediction\n",
        "        \"rel_acc\":       rel_acc,\n",
        "        \"rel_f1\":        rel_f1,\n",
        "        \"rel_precision\": rel_precision,\n",
        "        \"rel_recall\":    rel_recall\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5wRGzMiqZAT"
      },
      "source": [
        "##Definerer modellen når"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "h8dC_UZifoz1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import LayoutLMv3Model\n",
        "\n",
        "\n",
        "class RelationExtractionHead(nn.Module):\n",
        "    def __init__(self, hidden_size, num_relations):\n",
        "        super().__init__()\n",
        "        self.head_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.tail_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.bilinear = nn.Bilinear(hidden_size, hidden_size, num_relations)\n",
        "\n",
        "    def forward(self, h_i, h_j):\n",
        "        head = self.head_proj(h_i)\n",
        "        tail = self.tail_proj(h_j)\n",
        "        logits = self.bilinear(head, tail)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "_DzA5KFAdeA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import LayoutLMv3Model\n",
        "\n",
        "class LayoutWithRelationModel(nn.Module):\n",
        "    \"\"\"\n",
        "    LayoutLMv3-basert modell som bruker token-probabiliteter\n",
        "    (token_probs) sammen med span-hidden-states for relasjonsklassifisering.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = \"microsoft/layoutlmv3-base\",\n",
        "        hidden_size: int = 768,\n",
        "        num_labels: int = 5  # antall BIO-klasser\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # Grunnmodell\n",
        "        self.layout = LayoutLMv3Model.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # Token-klassifisering (BIO)\n",
        "        self.token_classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        # Relasjonslag: h_i, h_j, h_mul, h_diff, h_dot, p_i, p_j\n",
        "        rel_in = 4 * hidden_size + 1 + 2 * num_labels\n",
        "        self.rel_fc = nn.Sequential(\n",
        "            nn.Linear(rel_in, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids,\n",
        "        bbox,\n",
        "        pixel_values=None,\n",
        "        attention_mask=None,\n",
        "        labels=None,\n",
        "        entity_pairs=None,\n",
        "        rel_labels=None\n",
        "    ):\n",
        "        # 1) LayoutLMv3 encoding\n",
        "        outputs = self.layout(\n",
        "            input_ids=input_ids,\n",
        "            bbox=bbox,\n",
        "            pixel_values=pixel_values,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "        hidden_states = self.dropout(outputs.last_hidden_state)  # (B, seq_len, H)\n",
        "\n",
        "        # 2) Token-klassifisering\n",
        "        token_logits = self.token_classifier(hidden_states)    # (B, seq_len, L)\n",
        "        token_loss = None\n",
        "        if labels is not None:\n",
        "            token_loss = nn.CrossEntropyLoss()(  # BIO-tap\n",
        "                token_logits.view(-1, token_logits.size(-1)),\n",
        "                labels.view(-1)\n",
        "            )\n",
        "        # Probabiliteter for hver token og klasse\n",
        "        token_probs = F.softmax(token_logits, dim=-1)\n",
        "        token_preds = token_logits.argmax(dim=-1)\n",
        "\n",
        "        # 3) Relasjonsklassifisering\n",
        "        rel_logits, rel_preds, rel_loss = None, None, None\n",
        "        if entity_pairs is not None:\n",
        "            batch_scores = []\n",
        "            for b_idx, pairs in enumerate(entity_pairs):\n",
        "                h_b     = hidden_states[b_idx]  # (seq_len, H)\n",
        "                probs_b = token_probs[b_idx]    # (seq_len, L)\n",
        "                scores = []\n",
        "                for hi_idxs, ti_idxs in pairs:\n",
        "                    # Mean hidden for spans\n",
        "                    h_i = h_b[hi_idxs].mean(dim=0)\n",
        "                    h_j = h_b[ti_idxs].mean(dim=0)\n",
        "                    # Span-interaksjoner\n",
        "                    h_mul  = h_i * h_j\n",
        "                    h_diff = h_i - h_j\n",
        "                    h_dot  = torch.sum(h_i * h_j, dim=0, keepdim=True)\n",
        "                    # Mean token-prob for spans\n",
        "                    p_i = probs_b[hi_idxs].mean(dim=0)\n",
        "                    p_j = probs_b[ti_idxs].mean(dim=0)\n",
        "                    # Samle feature-vektor\n",
        "                    feats = torch.cat([h_i, h_j, h_mul, h_diff, h_dot, p_i, p_j], dim=0)\n",
        "                    scores.append(self.rel_fc(feats).squeeze())\n",
        "                batch_scores.append(torch.stack(scores))\n",
        "\n",
        "            # Pad for lik lengde\n",
        "            max_pairs = max(s.size(0) for s in batch_scores)\n",
        "            padded = []\n",
        "            for s in batch_scores:\n",
        "                if s.size(0) < max_pairs:\n",
        "                    pad = s.new_zeros(max_pairs - s.size(0))\n",
        "                    s = torch.cat([s, pad], dim=0)\n",
        "                padded.append(s)\n",
        "            rel_logits = torch.stack(padded)            # (B, max_pairs)\n",
        "            rel_preds = (torch.sigmoid(rel_logits) >= 0.5).long()\n",
        "            if rel_labels is not None:\n",
        "                rel_loss = nn.BCEWithLogitsLoss()(rel_logits, rel_labels.float())\n",
        "\n",
        "        # 4) Kombiner tap\n",
        "        loss = None\n",
        "        if token_loss is not None and rel_loss is not None:\n",
        "            loss = token_loss + 0.5 * rel_loss\n",
        "        else:\n",
        "            loss = token_loss if token_loss is not None else rel_loss\n",
        "\n",
        "        return {\n",
        "            \"loss\":          loss,\n",
        "            \"token_logits\":  token_logits,\n",
        "            \"token_preds\":   token_preds,\n",
        "            \"rel_logits\":    rel_logits,\n",
        "            \"rel_preds\":     rel_preds,\n",
        "            \"hidden_states\": hidden_states\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4gp7_LQdmII"
      },
      "source": [
        "#Trainer oppsett\n",
        "Inneholder:\n",
        "  - Modellen (LayoutLMv3ForTokenClassification)\n",
        "  - Args (hyperparametre som: epochs, batch_size, lr, lr_scheduler,    regularisering, eval_steps, metrics)\n",
        "  - Datasetsplit (train, eval)\n",
        "  - Tokenizer (from processor)\n",
        "  - Collator (litt usikker på denne)\n",
        "  - Metrikker for modellen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5JFnZ7a1qBZW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# === Freeze backbone if token-only training is needed (optional)\n",
        "def freeze_backbone(model):\n",
        "    for param in model.layout.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# === Full training loop\n",
        "\n",
        "def train_full_model(model, train_loader, eval_loader, optimizer, epochs=5, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
        "    model.to(device)\n",
        "    model.device = device  # <--- Ensure the model has a .device attribute\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch} Train\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                \"bbox\": batch[\"bbox\"].to(device),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "                \"labels\": batch[\"labels\"].to(device),\n",
        "                \"pixel_values\": batch.get(\"image\", None).to(device) if \"image\" in batch and batch[\"image\"] is not None else None,\n",
        "                \"entity_pairs\": batch.get(\"entity_pairs\"),\n",
        "                \"rel_labels\": batch.get(\"rel_labels\").to(device) if batch.get(\"rel_labels\") is not None else None\n",
        "            }\n",
        "            output = model(**inputs)\n",
        "            loss = output[\"loss\"]\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch} - Avg Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # === Evaluation\n",
        "        model.eval()\n",
        "        all_token_preds, all_token_labels = [], []\n",
        "        all_rel_preds, all_rel_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(eval_loader, desc=f\"Epoch {epoch} Eval\"):\n",
        "                inputs = {\n",
        "                    \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                    \"bbox\": batch[\"bbox\"].to(device),\n",
        "                    \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "                    \"labels\": batch[\"labels\"].to(device),\n",
        "                    \"pixel_values\": batch.get(\"image\", None).to(device) if \"image\" in batch and batch[\"image\"] is not None else None,\n",
        "                    \"entity_pairs\": batch.get(\"entity_pairs\"),\n",
        "                    \"rel_labels\": batch.get(\"rel_labels\").to(device) if batch.get(\"rel_labels\") is not None else None\n",
        "                }\n",
        "                output = model(**inputs)\n",
        "\n",
        "                # === Token metrics\n",
        "                logits = output[\"token_logits\"].argmax(-1).cpu()\n",
        "                label_ids = inputs[\"labels\"].cpu()\n",
        "                for p_seq, l_seq in zip(logits, label_ids):\n",
        "                    for p, l in zip(p_seq.tolist(), l_seq.tolist()):\n",
        "                        if l != -100:\n",
        "                            all_token_preds.append(p)\n",
        "                            all_token_labels.append(l)\n",
        "\n",
        "                # === Relation metrics (pairwise binary predictions)\n",
        "                if output[\"rel_logits\"] is not None and inputs[\"rel_labels\"] is not None:\n",
        "                    rel_logits = output[\"rel_logits\"]\n",
        "                    rel_labels = inputs[\"rel_labels\"]\n",
        "\n",
        "                    for pred_vec, label_vec in zip(torch.sigmoid(rel_logits), rel_labels):\n",
        "                        pred_bin = (pred_vec >= 0.5).long()\n",
        "                        all_rel_preds.extend(pred_bin.cpu().tolist())\n",
        "                        all_rel_labels.extend(label_vec.long().cpu().tolist())\n",
        "\n",
        "        # === Print token classification report\n",
        "        print(\"\\nToken Classification Report:\")\n",
        "        print(classification_report(all_token_labels, all_token_preds, target_names=list(id2label.values())))\n",
        "\n",
        "        # === Print relation classification report (if available)\n",
        "        if all_rel_preds:\n",
        "            print(\"\\nRelation Classification Report:\")\n",
        "            print(classification_report(all_rel_labels, all_rel_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "a00160c83aff4a1491c7e241054b87bc",
            "49b6aeb3a65f4cf4b5aa5ea4aec87117",
            "b6aa22cad796449983fb74ce5acdbca5",
            "ffc28c3a35214dc7b891de8456849b67",
            "11a8a2fe4a2b415b9667a229754f95a8",
            "14e0711937a640208ec9dbec0032f2d6",
            "1f5b06e787ad4a678b3a6cbf3727924d",
            "bad81e14bc5345168a29fb6ff4a38d5c",
            "33cb347a659e4d8ab6a29d3f1750ed5a",
            "1e43b581d9c14c978e76548b265fa4f3",
            "dd617b04ce034aa4a9585d6f4043e7df"
          ]
        },
        "id": "hg8bMcM5dmYW",
        "outputId": "312e55a4-d9f6-47b9-c1f2-fbda99c11df9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1 Train:   0%|          | 0/785 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a00160c83aff4a1491c7e241054b87bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1575: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "model = LayoutWithRelationModel(\n",
        "    model_name=\"microsoft/layoutlmv3-base\",\n",
        "    hidden_size=768,\n",
        "    num_labels=len(id2label)\n",
        ").to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "train_full_model(model, train_loader, eval_loader, optimizer, epochs=10, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n5t8TB-eyWu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "output_dir = \"/content/drive/MyDrive/KVP10k-layoutlmv3-v6\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Lagre modell\n",
        "torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
        "processor.save_pretrained(output_dir)\n",
        "\n",
        "# Lagre prosessor\n",
        "processor.save_pretrained(output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJinDzWcwpUL"
      },
      "source": [
        "#INFERENCE\n",
        "Laster inn beste fine-tuned modell og dens tilhørende processor fra Drive, samt tilleggsinformasjon som kreves av processoren.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gftv6oBQ8Rjl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/KVP10k-layoutlmv3-v6\"\n",
        "hidden_size = 768\n",
        "num_labels = len(id2label)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_path, local_files_only=True)\n",
        "\n",
        "model = LayoutWithRelationModel(\n",
        "    model_name=\"microsoft/layoutlmv3-base\",\n",
        "    hidden_size=hidden_size,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "model.load_state_dict(torch.load(f\"{model_path}/pytorch_model.bin\", map_location=\"cpu\"))\n",
        "model.to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzzMQnpi0xUz"
      },
      "source": [
        "#Kode prediksjon og visualisering av dette\n",
        "###*Tokenisering og input-prosessering med Layout sin Processor ved inference*\n",
        "Processor brukes her til å gjøre om tekst, bboxes, og bilde til format modell krever. Dette inkl:\n",
        "- Tokenisering\n",
        "- Normalisering av bboxes tilhørende hvert token\n",
        "- Skalering av bilde\n",
        "- Generering av input-tensorer\n",
        "\n",
        "NB: Denne prosessen gjøres allerede i Data_Processor notebooken som ferdigstilte datasettet for **denne** notebooken. Selve prosessen er dermed nesten indentisk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3DDG0gwdC0Y"
      },
      "outputs": [],
      "source": [
        "#Nødvendig for å plassere boksene på originalt-format på bilde-dokumentet\n",
        "def unnormalize_box(bbox, width, height):\n",
        "    return [\n",
        "        width * (bbox[0] / 1000),\n",
        "        height * (bbox[1] / 1000),\n",
        "        width * (bbox[2] / 1000),\n",
        "        height * (bbox[3] / 1000),\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSekHOh_dR71"
      },
      "source": [
        "#Velg vilkårlig dokument fra datasettet og prediker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l5scTZgoZx6"
      },
      "outputs": [],
      "source": [
        "# === Velg dokument\n",
        "#document_selected = \"aaf643426f0250efd10de3d9df63b407292f3fcc2aa335e399c37aca32443ea1\"\n",
        "document_selected = \"aaed61e79aa3edbae844f5775789ebb6aa1a94a23d9cb3468d2cfc974af304e5\"\n",
        "# document_selected = \"aa35720ba3611f946c372cc99d8cd1d78e81265b8ceb51dcdb4672d196944c2b\"\n",
        "# document_selected = \"faa5d71172e2e9959b41a5aec4fd2ab700534d1b2729484d2d5f26472cd56cfa\"\n",
        "# document_selected = \"ffe462e43b9dff12e78ea8fb69332abfb789da171a8597f5bb961853e06e6fa2\"\n",
        "# document_selected = \"feb2c4b21388318c7a51cc0aaf0e7c673a07f5204a40549a281bef065bb77925\"\n",
        "# document_selected = \"feaf84d435bd46100db82de51f5a989ff4d39fdcdb040a7044720b943e34b7d7\"\n",
        "# document_selected = \"df6b0a4cf1908bb95be874e4efa59411c685095d7bb596879961563503b5c239\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raGVbLf4mnTU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_token_head(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            bbox = batch[\"bbox\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            output = model(\n",
        "                input_ids=input_ids,\n",
        "                bbox=bbox,\n",
        "                attention_mask=attention_mask,\n",
        "                image=batch.get(\"image\")\n",
        "            )\n",
        "            token_logits = output[\"token_logits\"]\n",
        "            preds = token_logits.argmax(-1)\n",
        "\n",
        "            for p_seq, l_seq in zip(preds, labels):\n",
        "                for p, l in zip(p_seq.cpu().tolist(), l_seq.cpu().tolist()):\n",
        "                    if l != -100:\n",
        "                        all_preds.append(p)\n",
        "                        all_labels.append(l)\n",
        "\n",
        "    print(classification_report(all_labels, all_preds, target_names=list(id2label.values())))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYy05IO9ofy4"
      },
      "outputs": [],
      "source": [
        "evaluate_token_head(model, eval_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvxo2tvfdDWA"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "\n",
        "def predict_tokens(doc_id, show_gt=True):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    base_path = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/test\"\n",
        "    image_path = f\"{base_path}/images/{doc_id}.png\"\n",
        "    ocr_path = f\"{base_path}/ocrs/{doc_id}.json\"\n",
        "    gt_path = f\"{base_path}/gts/{doc_id}.json\"\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ocr_data = json.load(f)\n",
        "    with open(gt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        gt_data = json.load(f)\n",
        "\n",
        "    page = ocr_data[\"pages\"][0]\n",
        "    words = [w[\"text\"] for w in page[\"words\"]]\n",
        "    raw_boxes = [w[\"bbox\"] for w in page[\"words\"]]\n",
        "    width, height = page[\"width\"], page[\"height\"]\n",
        "    norm_boxes = [normalize_bbox(b, width, height) for b in raw_boxes]\n",
        "\n",
        "    string_labels = iob_from_kvps(words, raw_boxes, gt_data[\"kvps_list\"])\n",
        "    word_labels = [label_map.get(lbl, 0) for lbl in string_labels]\n",
        "\n",
        "    encoding = processor(\n",
        "        image,\n",
        "        words,\n",
        "        boxes=norm_boxes,\n",
        "        word_labels=word_labels,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    word_ids = encoding.word_ids()\n",
        "    labels = [-100] * len(word_ids)\n",
        "    for idx, word_idx in enumerate(word_ids):\n",
        "        if word_idx is None:\n",
        "            continue\n",
        "        label_str = string_labels[word_idx]\n",
        "        labels[idx] = label_map[label_str]\n",
        "    encoding[\"labels\"] = torch.tensor([labels])\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in encoding.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            bbox=inputs[\"bbox\"],\n",
        "            image=inputs[\"pixel_values\"],\n",
        "            attention_mask=inputs[\"attention_mask\"]\n",
        "        )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].squeeze().tolist()\n",
        "    predictions = outputs[\"token_logits\"].argmax(-1).squeeze().tolist()\n",
        "    bboxes = inputs[\"bbox\"].squeeze().tolist()\n",
        "    unnorm_boxes = [unnormalize_box(b, width, height) for b in bboxes]\n",
        "    tokens = [processor.tokenizer.decode([tid]) for tid in input_ids]\n",
        "\n",
        "    filtered = [\n",
        "        (token, id2label.get(pred, \"O\"), box)\n",
        "        for token, pred, box in zip(tokens, predictions, unnorm_boxes)\n",
        "        if token not in [\"[PAD]\", \"[CLS]\", \"[SEP]\"]\n",
        "    ]\n",
        "\n",
        "    print(\"Unike labels i output:\", set(p[1] for p in filtered))\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "    def iob_to_label(label):\n",
        "        return label[2:].lower() if label.startswith((\"B-\", \"I-\")) else \"other\"\n",
        "\n",
        "    label2color = {\n",
        "        \"key\": \"blue\",\n",
        "        \"value\": \"green\",\n",
        "        \"other\": \"gray\"\n",
        "    }\n",
        "\n",
        "    for token, pred_label, box in filtered:\n",
        "        if pred_label == \"O\":\n",
        "            continue\n",
        "        label_type = iob_to_label(pred_label)\n",
        "        draw.rectangle(box, outline=label2color.get(label_type, \"red\"), width=2)\n",
        "        draw.text((box[0] + 5, box[1] - 10), label_type, fill=label2color.get(label_type, \"red\"), font=font)\n",
        "\n",
        "    print(\"Modellens prediksjoner:\")\n",
        "    display(image)\n",
        "\n",
        "    if show_gt:\n",
        "        gt_img = Image.open(image_path).convert(\"RGB\")\n",
        "        draw_gt = ImageDraw.Draw(gt_img)\n",
        "        for word, box, label_id in zip(words, raw_boxes, string_labels):\n",
        "            if label_id == \"O\":\n",
        "                continue\n",
        "            label_type = iob_to_label(label_id)\n",
        "            draw_gt.rectangle(box, outline=label2color.get(label_type, \"gray\"), width=2)\n",
        "            draw_gt.text((box[0] + 5, box[1] - 10), label_type, fill=label2color.get(label_type, \"gray\"), font=font)\n",
        "\n",
        "        print(\"Ground Truth:\")\n",
        "        display(gt_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QS92Sq_JwuBV"
      },
      "outputs": [],
      "source": [
        "predict_tokens(document_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPD79RD5dNGu"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "import json, torch, math\n",
        "\n",
        "def predict_relations(doc_id: str, threshold: float = 0.5):\n",
        "    # ─── helper to extract BIO spans ──────────────────────────────\n",
        "    def extract_spans(labels, kind):\n",
        "        spans, cur = [], []\n",
        "        for idx, lab in enumerate(labels):\n",
        "            if lab == f\"B-{kind}\":\n",
        "                if cur: spans.append(cur)\n",
        "                cur = [idx]\n",
        "            elif lab == f\"I-{kind}\" and cur:\n",
        "                cur.append(idx)\n",
        "            else:\n",
        "                if cur: spans.append(cur)\n",
        "                cur = []\n",
        "        if cur: spans.append(cur)\n",
        "        return spans\n",
        "\n",
        "    # ─── load image & OCR ─────────────────────────────────────────\n",
        "    base      = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/test\"\n",
        "    img_path  = f\"{base}/images/{doc_id}.png\"\n",
        "    ocr_path  = f\"{base}/ocrs/{doc_id}.json\"\n",
        "    image     = Image.open(img_path).convert(\"RGB\")\n",
        "    with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ocr = json.load(f)\n",
        "\n",
        "    page       = ocr[\"pages\"][0]\n",
        "    words      = [w[\"text\"] for w in page[\"words\"]]\n",
        "    raw_boxes  = [w[\"bbox\"] for w in page[\"words\"]]\n",
        "    W, H       = page[\"width\"], page[\"height\"]\n",
        "    norm_boxes = [normalize_bbox(b, W, H) for b in raw_boxes]\n",
        "\n",
        "    # ─── run processor & model (batch size = 1) ───────────────────\n",
        "    enc = processor(\n",
        "        image, words, boxes=norm_boxes,\n",
        "        return_tensors=\"pt\", truncation=True, padding=\"max_length\"\n",
        "    )\n",
        "    token_boxes = enc[\"bbox\"][0].cpu().tolist()\n",
        "    for k in (\"input_ids\",\"bbox\",\"pixel_values\",\"attention_mask\"):\n",
        "        enc[k] = enc[k].to(device)\n",
        "\n",
        "    # ─── 1) hent ut token-labels og spans ─────────────────────────\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out_tokens = model(\n",
        "            input_ids     = enc[\"input_ids\"],\n",
        "            bbox          = enc[\"bbox\"],\n",
        "            image  = enc[\"pixel_values\"],\n",
        "            attention_mask= enc[\"attention_mask\"]\n",
        "        )\n",
        "    # decode BIO-prediksjoner\n",
        "    pred_ids     = out_tokens[\"token_logits\"][0].argmax(-1).tolist()\n",
        "    labels_pred  = [id2label.get(i, \"O\") for i in pred_ids]\n",
        "    key_spans    = extract_spans(labels_pred, \"KEY\")\n",
        "    value_spans  = extract_spans(labels_pred, \"VALUE\")\n",
        "\n",
        "    # ─── 2) lag entity_pairs-listen slik modellen forventer ───────\n",
        "    pairs = [(k_span, v_span) for k_span in key_spans for v_span in value_spans]\n",
        "\n",
        "    # ─── 3) kjør forward på nytt med entity_pairs for relasjons‐logits ─\n",
        "    with torch.no_grad():\n",
        "        out = model(\n",
        "            input_ids     = enc[\"input_ids\"],\n",
        "            bbox          = enc[\"bbox\"],\n",
        "            image  = enc[\"pixel_values\"],\n",
        "            attention_mask= enc[\"attention_mask\"],\n",
        "            entity_pairs  = [pairs]  # batch av lengde 1\n",
        "        )\n",
        "\n",
        "    rel_logits = out[\"rel_logits\"][0]  # tensor of shape (num_pairs,)\n",
        "    relations  = []\n",
        "    for idx, (k_span, v_span) in enumerate(pairs):\n",
        "        prob = torch.sigmoid(rel_logits[idx]).item()\n",
        "        if prob >= threshold:\n",
        "            relations.append((k_span, v_span, prob))\n",
        "\n",
        "    # ─── 4) tegne resultatene ──────────────────────────────────────\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "    arrow_len   = 15\n",
        "    arrow_angle = math.radians(25)\n",
        "\n",
        "    if not relations:\n",
        "        draw.text((10,10), \"Ingen relasjoner funnet\", fill=\"orange\", font=font)\n",
        "    else:\n",
        "        for k_span, v_span, prob in relations:\n",
        "            # bokser\n",
        "            for i in k_span:\n",
        "                draw.rectangle(unnormalize_box(token_boxes[i], W, H),\n",
        "                               outline=\"blue\", width=2)\n",
        "            for i in v_span:\n",
        "                draw.rectangle(unnormalize_box(token_boxes[i], W, H),\n",
        "                               outline=\"green\", width=2)\n",
        "\n",
        "            # pil fra key til value (samme som før)\n",
        "            kxs = [(b[0]+b[2])/2 for idx in k_span for b in [token_boxes[idx]]]\n",
        "            kys = [(b[1]+b[3])/2 for idx in k_span for b in [token_boxes[idx]]]\n",
        "            vxs = [(b[0]+b[2])/2 for idx in v_span for b in [token_boxes[idx]]]\n",
        "            vys = [(b[1]+b[3])/2 for idx in v_span for b in [token_boxes[idx]]]\n",
        "            kc  = ((sum(kxs)/len(kxs))*W/1000, (sum(kys)/len(kys))*H/1000)\n",
        "            vc  = ((sum(vxs)/len(vxs))*W/1000, (sum(vys)/len(vys))*H/1000)\n",
        "\n",
        "            dx, dy = vc[0]-kc[0], vc[1]-kc[1]\n",
        "            dist    = math.hypot(dx, dy)\n",
        "            if dist > arrow_len:\n",
        "                ux, uy    = dx/dist, dy/dist\n",
        "                tail      = (kc[0], kc[1])\n",
        "                head_base = (vc[0]-ux*arrow_len, vc[1]-uy*arrow_len)\n",
        "                draw.line([tail, head_base], fill=\"red\", width=2)\n",
        "            else:\n",
        "                head_base = kc\n",
        "\n",
        "            ux, uy = (vc[0]-head_base[0])/arrow_len, (vc[1]-head_base[1])/arrow_len\n",
        "            left_x  = vc[0] - arrow_len*(ux*math.cos(arrow_angle) + uy*math.sin(arrow_angle))\n",
        "            left_y  = vc[1] - arrow_len*(uy*math.cos(arrow_angle) - ux*math.sin(arrow_angle))\n",
        "            right_x = vc[0] - arrow_len*(ux*math.cos(arrow_angle) - uy*math.sin(arrow_angle))\n",
        "            right_y = vc[1] - arrow_len*(uy*math.cos(arrow_angle) + ux*math.sin(arrow_angle))\n",
        "            draw.polygon([vc, (left_x,left_y), (right_x,right_y)], fill=\"red\")\n",
        "\n",
        "            draw.text((vc[0]+3, vc[1]-10), f\"{prob:.2f}\",\n",
        "                      fill=\"red\", font=font)\n",
        "\n",
        "    display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmPFBUPRcUJi"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "import json, torch, math\n",
        "\n",
        "def predict_relations_per_key(doc_id: str, threshold: float = 0.5):\n",
        "    # ─── helper for å hente ut BIO-spans, kun der mask==1 ─────────────\n",
        "    def extract_spans(labels, mask, kind):\n",
        "        spans, cur = [], []\n",
        "        for idx, (lab, m) in enumerate(zip(labels, mask)):\n",
        "            if m == 0:             # pad‐token ⇒ avslutt span\n",
        "                if cur:\n",
        "                    spans.append(cur)\n",
        "                    cur = []\n",
        "                continue\n",
        "            if lab == f\"B-{kind}\":\n",
        "                if cur:\n",
        "                    spans.append(cur)\n",
        "                cur = [idx]\n",
        "            elif lab == f\"I-{kind}\" and cur:\n",
        "                cur.append(idx)\n",
        "            else:\n",
        "                if cur:\n",
        "                    spans.append(cur)\n",
        "                    cur = []\n",
        "        if cur:\n",
        "            spans.append(cur)\n",
        "        return spans\n",
        "\n",
        "    # ─── 1) Load image + OCR ────────────────────────────────────────\n",
        "    base      = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/test\"\n",
        "    img_path  = f\"{base}/images/{doc_id}.png\"\n",
        "    ocr_path  = f\"{base}/ocrs/{doc_id}.json\"\n",
        "    image     = Image.open(img_path).convert(\"RGB\")\n",
        "    with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ocr = json.load(f)\n",
        "\n",
        "    page       = ocr[\"pages\"][0]\n",
        "    words      = [w[\"text\"]  for w in page[\"words\"]]\n",
        "    raw_boxes  = [w[\"bbox\"]  for w in page[\"words\"]]\n",
        "    W, H       = page[\"width\"], page[\"height\"]\n",
        "    norm_boxes = [normalize_bbox(b, W, H) for b in raw_boxes]\n",
        "\n",
        "    # ─── 2) Token‐klassifisering for spans ───────────────────────────\n",
        "    enc = processor(\n",
        "        image, words, boxes=norm_boxes,\n",
        "        return_tensors=\"pt\", truncation=True, padding=\"max_length\"\n",
        "    )\n",
        "    token_boxes = enc[\"bbox\"][0].cpu().tolist()\n",
        "    for k in (\"input_ids\",\"bbox\",\"pixel_values\",\"attention_mask\"):\n",
        "        enc[k] = enc[k].to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out_tokens = model(\n",
        "            input_ids     = enc[\"input_ids\"],\n",
        "            bbox          = enc[\"bbox\"],\n",
        "            image  = enc[\"pixel_values\"],\n",
        "            attention_mask= enc[\"attention_mask\"]\n",
        "        )\n",
        "\n",
        "    # hent prediksjoner + mask\n",
        "    pred_ids    = out_tokens[\"token_logits\"][0].argmax(-1).tolist()\n",
        "    mask        = enc[\"attention_mask\"][0].cpu().tolist()\n",
        "    labels_pred = [id2label.get(i, \"O\") for i in pred_ids]\n",
        "\n",
        "    # finn spans, kun der mask==1\n",
        "    key_spans   = extract_spans(labels_pred, mask, \"KEY\")\n",
        "    value_spans = extract_spans(labels_pred, mask, \"VALUE\")\n",
        "\n",
        "    # ─── 3) Bygg (key,value)-par og hent rel_logits ─────────────────\n",
        "    pairs = [(k, v) for k in key_spans for v in value_spans]\n",
        "    with torch.no_grad():\n",
        "        out = model(\n",
        "            input_ids     = enc[\"input_ids\"],\n",
        "            bbox          = enc[\"bbox\"],\n",
        "            image  = enc[\"pixel_values\"],\n",
        "            attention_mask= enc[\"attention_mask\"],\n",
        "            entity_pairs  = [pairs],\n",
        "        )\n",
        "    rel_logits = out[\"rel_logits\"][0]  # (len(pairs),)\n",
        "\n",
        "    # ─── 4) Velg beste VALUE per KEY (over threshold) ───────────────\n",
        "    best_for_key = {}\n",
        "    for idx, (k_span, v_span) in enumerate(pairs):\n",
        "        prob = torch.sigmoid(rel_logits[idx]).item()\n",
        "        key_t = tuple(k_span)\n",
        "        if key_t not in best_for_key or prob > best_for_key[key_t][2]:\n",
        "            best_for_key[key_t] = (k_span, v_span, prob)\n",
        "\n",
        "    relations = [\n",
        "        (k, v, p) for (k, v, p) in best_for_key.values()\n",
        "        if p >= threshold\n",
        "    ]\n",
        "\n",
        "    # ─── 5) Tegn ALLE spans + pil per KEY→beste VALUE ──────────────\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "    arrow_len   = 15\n",
        "    arrow_angle = math.radians(25)\n",
        "\n",
        "    # 5a) alle KEY i blått\n",
        "    for k_span in key_spans:\n",
        "        for i in k_span:\n",
        "            draw.rectangle(\n",
        "                unnormalize_box(token_boxes[i], W, H),\n",
        "                outline=\"blue\", width=2\n",
        "            )\n",
        "\n",
        "    # 5b) alle VALUE i grønt\n",
        "    for v_span in value_spans:\n",
        "        for i in v_span:\n",
        "            draw.rectangle(\n",
        "                unnormalize_box(token_boxes[i], W, H),\n",
        "                outline=\"green\", width=2\n",
        "            )\n",
        "\n",
        "    # 5c) én pil per nøkkel→ value\n",
        "    if not relations:\n",
        "        draw.text((10,10), \"Ingen relasjoner funnet\", fill=\"orange\", font=font)\n",
        "    else:\n",
        "        for k_span, v_span, prob in relations:\n",
        "            # finn senterpunkt\n",
        "            kxs = [(b[0]+b[2])/2 for idx in k_span for b in [token_boxes[idx]]]\n",
        "            kys = [(b[1]+b[3])/2 for idx in k_span for b in [token_boxes[idx]]]\n",
        "            vxs = [(b[0]+b[2])/2 for idx in v_span for b in [token_boxes[idx]]]\n",
        "            vys = [(b[1]+b[3])/2 for idx in v_span for b in [token_boxes[idx]]]\n",
        "            kc  = ((sum(kxs)/len(kxs))*W/1000, (sum(kys)/len(kys))*H/1000)\n",
        "            vc  = ((sum(vxs)/len(vxs))*W/1000, (sum(vys)/len(vys))*H/1000)\n",
        "\n",
        "            dx, dy = vc[0]-kc[0], vc[1]-kc[1]\n",
        "            dist    = math.hypot(dx, dy)\n",
        "            if dist > arrow_len:\n",
        "                ux, uy    = dx/dist, dy/dist\n",
        "                tail      = (kc[0], kc[1])\n",
        "                head_base = (vc[0]-ux*arrow_len, vc[1]-uy*arrow_len)\n",
        "                draw.line([tail, head_base], fill=\"red\", width=2)\n",
        "            else:\n",
        "                head_base = kc\n",
        "\n",
        "            # pilhode\n",
        "            ux, uy = (vc[0]-head_base[0])/arrow_len, (vc[1]-head_base[1])/arrow_len\n",
        "            left_x  = vc[0] - arrow_len*( ux*math.cos(arrow_angle) + uy*math.sin(arrow_angle))\n",
        "            left_y  = vc[1] - arrow_len*( uy*math.cos(arrow_angle) - ux*math.sin(arrow_angle))\n",
        "            right_x = vc[0] - arrow_len*( ux*math.cos(arrow_angle) - uy*math.sin(arrow_angle))\n",
        "            right_y = vc[1] - arrow_len*( uy*math.cos(arrow_angle) + ux*math.sin(arrow_angle))\n",
        "            draw.polygon([vc, (left_x,left_y), (right_x,right_y)], fill=\"red\")\n",
        "\n",
        "            draw.text((vc[0]+3, vc[1]-10), f\"{prob:.2f}\",\n",
        "                      fill=\"red\", font=font)\n",
        "\n",
        "    display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scERip5ToTsO"
      },
      "outputs": [],
      "source": [
        "predict_relations(document_selected)\n",
        "predict_relations_per_key(document_selected)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50976af228364669b660c60d6912d79d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c91273fb1b814c86a2516611a8138b33",
              "IPY_MODEL_b1c9dcf8fc754d5eb7a5b8298f9568cf",
              "IPY_MODEL_7fecc948801345c4baa7979cdb8a3e2f"
            ],
            "layout": "IPY_MODEL_e16b732e548146908e9beaf30cf44450"
          }
        },
        "c91273fb1b814c86a2516611a8138b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda1823c3ed647568dd7a024f87186c7",
            "placeholder": "​",
            "style": "IPY_MODEL_b20e9d7517324e88a88985e21716afeb",
            "value": "Map: 100%"
          }
        },
        "b1c9dcf8fc754d5eb7a5b8298f9568cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638f0b0bee94429cbff75fc4877c1023",
            "max": 6273,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_691190f7ad87413983d1117d99462334",
            "value": 6273
          }
        },
        "7fecc948801345c4baa7979cdb8a3e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a82fcdab4764a039d0645663cce00eb",
            "placeholder": "​",
            "style": "IPY_MODEL_4c8629355e114774bda009ffc5a22040",
            "value": " 6273/6273 [00:51&lt;00:00, 78.22 examples/s]"
          }
        },
        "e16b732e548146908e9beaf30cf44450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda1823c3ed647568dd7a024f87186c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b20e9d7517324e88a88985e21716afeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "638f0b0bee94429cbff75fc4877c1023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "691190f7ad87413983d1117d99462334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a82fcdab4764a039d0645663cce00eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c8629355e114774bda009ffc5a22040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b6ebc0406c14f1eaf252ae0fb1f2ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1b370c17ae346a290494bb219fef36d",
              "IPY_MODEL_eed947af794944729c200c17710d144d",
              "IPY_MODEL_a4467d115ad4409e9af2ec26666a8dbf"
            ],
            "layout": "IPY_MODEL_85c4547dbc6042eda9134c8ece77e34e"
          }
        },
        "c1b370c17ae346a290494bb219fef36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0cab32a45b542c59277ad00facf8ed2",
            "placeholder": "​",
            "style": "IPY_MODEL_026ab7fe2a7f45e48fc33c43b6328237",
            "value": "Map: 100%"
          }
        },
        "eed947af794944729c200c17710d144d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb10feafc8b545a0875315f9da4978e0",
            "max": 1569,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69a336e859c14418a72a8a20ca8d9051",
            "value": 1569
          }
        },
        "a4467d115ad4409e9af2ec26666a8dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8882e58ddd194a0e884dd9011cf264a6",
            "placeholder": "​",
            "style": "IPY_MODEL_bf4be281d7b644e0acecf622ffca354e",
            "value": " 1569/1569 [00:12&lt;00:00, 166.78 examples/s]"
          }
        },
        "85c4547dbc6042eda9134c8ece77e34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0cab32a45b542c59277ad00facf8ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "026ab7fe2a7f45e48fc33c43b6328237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb10feafc8b545a0875315f9da4978e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a336e859c14418a72a8a20ca8d9051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8882e58ddd194a0e884dd9011cf264a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4be281d7b644e0acecf622ffca354e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9770f8e4be364e208355c6c034d5258c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b980227ae8f94e279164b95d94407c4e",
              "IPY_MODEL_89a9c1f5564947c094af587faa89cd55",
              "IPY_MODEL_3a9703984c514ddbafe99e03ba289383"
            ],
            "layout": "IPY_MODEL_17e44e97deec42d5a528b374cb9f4e8d"
          }
        },
        "b980227ae8f94e279164b95d94407c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_429b8ba614794f148f1cc65c4e7f6cfc",
            "placeholder": "​",
            "style": "IPY_MODEL_44e2e6b0d58e43c2ae2349098c9dd41c",
            "value": "Map: 100%"
          }
        },
        "89a9c1f5564947c094af587faa89cd55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53bb0e95769d41359268603e1b12bdd0",
            "max": 828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0659cf55ff534bfeb5078a0c563b1aeb",
            "value": 828
          }
        },
        "3a9703984c514ddbafe99e03ba289383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326667ef8b724c81a124499b1e2712b1",
            "placeholder": "​",
            "style": "IPY_MODEL_0f9ca318b71d429d9190f10ebff7f369",
            "value": " 828/828 [00:07&lt;00:00, 734.66 examples/s]"
          }
        },
        "17e44e97deec42d5a528b374cb9f4e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429b8ba614794f148f1cc65c4e7f6cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e2e6b0d58e43c2ae2349098c9dd41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53bb0e95769d41359268603e1b12bdd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0659cf55ff534bfeb5078a0c563b1aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "326667ef8b724c81a124499b1e2712b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f9ca318b71d429d9190f10ebff7f369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a00160c83aff4a1491c7e241054b87bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49b6aeb3a65f4cf4b5aa5ea4aec87117",
              "IPY_MODEL_b6aa22cad796449983fb74ce5acdbca5",
              "IPY_MODEL_ffc28c3a35214dc7b891de8456849b67"
            ],
            "layout": "IPY_MODEL_11a8a2fe4a2b415b9667a229754f95a8"
          }
        },
        "49b6aeb3a65f4cf4b5aa5ea4aec87117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e0711937a640208ec9dbec0032f2d6",
            "placeholder": "​",
            "style": "IPY_MODEL_1f5b06e787ad4a678b3a6cbf3727924d",
            "value": "Epoch 1 Train:   1%"
          }
        },
        "b6aa22cad796449983fb74ce5acdbca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad81e14bc5345168a29fb6ff4a38d5c",
            "max": 785,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33cb347a659e4d8ab6a29d3f1750ed5a",
            "value": 10
          }
        },
        "ffc28c3a35214dc7b891de8456849b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e43b581d9c14c978e76548b265fa4f3",
            "placeholder": "​",
            "style": "IPY_MODEL_dd617b04ce034aa4a9585d6f4043e7df",
            "value": " 10/785 [00:16&lt;18:19,  1.42s/it]"
          }
        },
        "11a8a2fe4a2b415b9667a229754f95a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14e0711937a640208ec9dbec0032f2d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5b06e787ad4a678b3a6cbf3727924d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad81e14bc5345168a29fb6ff4a38d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33cb347a659e4d8ab6a29d3f1750ed5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e43b581d9c14c978e76548b265fa4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd617b04ce034aa4a9585d6f4043e7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}