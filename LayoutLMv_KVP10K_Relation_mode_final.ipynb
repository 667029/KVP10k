{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VofLEluS_HIY"
      },
      "source": [
        "#Dokumentforståelse med LayoutLMv3 på KVP10k-datasettet\n",
        "\n",
        "Denne notebooken demonstrerer hvordan vi henter inn en preprossessert og tilpasset versjon av KVP10k-datasettet i Hugging Face-format, til å utføre **Key-Value Pair Extraction (KVP)** på  dokumentbilder.\n",
        "\n",
        "- Datasettet består av over 10k forretningsdokumenter, og inneholder blant annet dokumentbilder og tilhørende nøkkel-verdi-par, som brukes av denne fine-tuned modellen som utvikles her.\n",
        "\n",
        "- Sluttmålet er å utvikle og trene en ny modell til dokumentforståelse, ved å forstå **visuell layout**, **tekstlig innhold**, og **relasjoner mellom nøkler og verdier** i dokumentene.\n",
        "  - KVP-Extraction modellen som utvikles i denne notebooken er tenkt å brukes grunnmur i sluttmodellen, for å med stor sannsynlighet beherske å linke mellom nøkkel-verdi-par i ulike dokumenter.\n",
        "\n",
        "LayoutLMv3 er en multi-modal modell designet for å kombinere tekst, layout og annen bilde-informasjon\n",
        "\n",
        "---\n",
        "\n",
        "###**Notbooken dekker følgende steg**:\n",
        "\n",
        "1. Installasjon av de nødendige biblioteker\n",
        "2. Lasting av forhåndsprosessert datasett\n",
        "3. Tokenisering av tekst og input-formatering med Layout sin Processor\n",
        "- 3.1 Logikk for å anngi predikerte BIO-labels til dokumentets bbox'es\n",
        "4. Trening av modell for token-klassifisering\n",
        "5. Evaluering og lagring av modell i Drive\n",
        "6. Visualisering av modell under inferense\n",
        "\n",
        "---\n",
        "\n",
        "###**LayoutLMv3Processor - gjør følgende**:\n",
        "1. Tekst-tokenisering: Tekst fra dokumentet tokeniseres.\n",
        "2. Token-connection: Hvert token kobles til en bounding box (bbox) på dokumentet, gjennom *boxes*-parmeteret som inneholder (x0,y0,x1,y1)-kordinater til hvert token.\n",
        "3. Image-embedding: Dokumentbildet skaleres og legges og blir input til modellen\n",
        "4. Label-alignment: Hvert token får en BIO-label, som brukes under modellens token-klassifisering\n",
        "\n",
        "Tokeniseringen handler om å forvandle dokumentet til tokens med alle nødvendige modaliteter (tekst, layout og bilde) slik at modellen lærer sammenhengen mellom dem gjennom trening.\n",
        "\n",
        "**Det brukes BIO-tagger, og dette er hva det står for:**\n",
        " - B --> Begin: første token i en entitet.\n",
        " - I --> Inside: inne i en entitet.\n",
        " - O --> Outside: tokenen er ikke en del av noen entitet\n",
        "\n",
        "f.eks.\n",
        "  - Tokens:  [\"Name\", \"of\", \"buyer\", \":\", \"Ole\", \"Martin\", \"Lystadmoen\"]\n",
        "  - Labels:  [\"B-KEY\", \"I-KEY\", \"I-KEY\", \"O\", \"B-VALUE\", \"I-VALUE\", \"I-VALUE\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caef954e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0NSOqNmukkk"
      },
      "source": [
        "# Dataset - forståelse\n",
        "\n",
        "**Innhold i train/-mappen i KVP10k:**\n",
        "_____\n",
        "  - *images*/ --> .png bilder av hvert dokument. Visuell input for modellen.\n",
        "    - Det modellen \"ser\".\n",
        "_____\n",
        "\n",
        "  - *ocrs*/ --> JSON-filer med **words** og **bboxes** for hvert dokument. Gir tekst og posisjoner fra OCR, og brukes sammen med images.\n",
        "    - Det modellen \"leser\" (tokens og posisjonene deres).\n",
        "\n",
        "_____\n",
        "\n",
        "  - *gts*/ --> JSON-filer med KVPs og tilhørende bboxes. Inneholder hvilke keys og values som hører sammen.\n",
        "    - Det som lærer modellen hvilke tokens som er nøkler, verdier, og hvilket som er koblet sammen.\n",
        "_____\n",
        "\n",
        "  - *items*/ --> JSON-filer med annotasjoner og layout-objs (rektangler, linker, etiketter)\n",
        "    - tilleggsinformasjon\n",
        "    - ikke viktig i for EE\n",
        "    - Helt nødvendig i RE-delen av dette prosjektet\n",
        "_____"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TqejcrWXvnoL"
      },
      "outputs": [],
      "source": [
        "#transformers: Hugging Face bibliotek som gir tilgang til LayoutLMv3\n",
        "#datasets: For håndtering av dataset i Huggig Face-format\n",
        "#seqeval: evalueringsbibliotek for sekvensmerking, brukes for måle metrikker for i dette tilfelle BIO-tagging\n",
        "!pip install -q -U transformers datasets seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av-n3h6jaou3"
      },
      "outputs": [],
      "source": [
        "#Håndterer ulike metrikker inkl. integrasjon med seqeval\n",
        "!pip install -q evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE27SIYc2Y2y"
      },
      "outputs": [],
      "source": [
        "import os              #navigere mapper og filer, hente filbaner\n",
        "from PIL import Image  #åpne, vise og manipulere bilder\n",
        "import json            #lese/skrive til JSON-filer\n",
        "from transformers import LayoutLMv3Processor\n",
        "import torch           #modellens input-format for data\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Uup0eV5_usd"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmYZ6LnbaWTv"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "metric = load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW4eqj9o2trD"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/\"\n",
        "print(os.listdir(base_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYm7ncZw_lSW"
      },
      "outputs": [],
      "source": [
        "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False) # <-- Viktig fordi vi allerede har utført OCR på bildet og har tekst og bboxes\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsRz3cC2_8mj"
      },
      "outputs": [],
      "source": [
        "# Mapping fra tekstlige BIO-labels til tall som modellen bruker\n",
        "label_map = {\n",
        "    \"O\": 0,\n",
        "    \"B-KEY\": 1,\n",
        "    \"I-KEY\": 2,\n",
        "    \"B-VALUE\": 3,\n",
        "    \"I-VALUE\": 4,\n",
        "}\n",
        "\n",
        "# Funksjon for å skalere bounding boxes til 0-1000 (som LayoutLMv3 krever)\n",
        "def normalize_bbox(bbox, width, height):\n",
        "  return [\n",
        "      int(1000 * (bbox[0] /width)),\n",
        "      int(1000 * (bbox[1] / height)),\n",
        "      int(1000 * (bbox[2] / width)),\n",
        "      int(1000 * (bbox[3] / height))\n",
        "  ]\n",
        "\n",
        "\n",
        "def assign_label_for_box(box, boxes, label_type):\n",
        "  \"\"\"Returnerer liste med (index, label) for tokens som overlapper box\"\"\"\n",
        "  overlaps = []\n",
        "  for i, token_box in enumerate(boxes):\n",
        "    if box_overlap(box, token_box) > 0:\n",
        "      overlaps.append(i)\n",
        "\n",
        "  overlaps = sorted(overlaps)\n",
        "\n",
        "  labeled = []\n",
        "  for j, idx in enumerate(overlaps):\n",
        "    tag = f\"B-{label_type}\" if j == 0 else f\"I-{label_type}\"\n",
        "    labeled.append((idx, tag))\n",
        "\n",
        "  return labeled\n",
        "\n",
        "\n",
        "#Sjekker om OCR-boksen overlapper med GTS(key/value)-boksen.\n",
        "#Ved overlapp hører de til hverandre.\n",
        "def box_overlap(box1, box2):\n",
        "  x0 = max(box1[0], box2[0])\n",
        "  y0 = max(box1[1], box2[1])\n",
        "  x1 = min(box1[2], box2[2])\n",
        "  y1 = min(box1[3], box2[3])\n",
        "  return max(0, x1 - x0) * max(0, y1 - y0)\n",
        "\n",
        "\n",
        "# Funksjon for å generere BIO-labels fra gts (ground truth).\n",
        "# Lager en BIO-label for hvert token basert på om det overlapper med en key- eller value-boks fra GTS.\n",
        "# Matcher hvert token fra OCR (word + bbox) mot key/value-bbokser fra gts:\n",
        "# --> Token overlapper en nøkkelboks: B-KEY eller I-KEY\n",
        "# --> Token overlapper en verdiboks: B-VALUE eller I-VALUE\n",
        "# --> Ellers: O\n",
        "def iob_from_kvps(words, boxes, kvps):\n",
        "  labels = [\"O\"] * len(words)\n",
        "\n",
        "  #Gå igjennom alle key-value-pairs\n",
        "  for kvp in kvps:\n",
        "    if \"key\" in kvp and \"bbox\" in kvp[\"key\"]:\n",
        "      key_bbox = kvp[\"key\"][\"bbox\"]\n",
        "      for idx, tag in assign_label_for_box(key_bbox, boxes, \"KEY\"):\n",
        "        labels[idx] = tag\n",
        "\n",
        "    if \"value\" in kvp and \"bbox\" in kvp[\"value\"]:\n",
        "      value_box = kvp[\"value\"][\"bbox\"]\n",
        "      for idx, tag in assign_label_for_box(value_box, boxes, \"VALUE\"):\n",
        "        labels[idx] = tag\n",
        "\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94wyjeWiRmJG"
      },
      "outputs": [],
      "source": [
        "!ls -lh /content/drive/MyDrive/KVP10k_processed_ready\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl8UG_z9fMpK"
      },
      "source": [
        "#Innlasting av et allerede pre-prossesert KVP10k-dataset spesielt utviklet for LayoutLMv3 (KVP-extraction).\n",
        "\n",
        "\n",
        "Henter allerede preprosserert dataset for layout modellen og legger til entiteter og labels for relasjonslaget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrLS234HQhcG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from datasets import load_from_disk\n",
        "\n",
        "# Monter Drive (hvis du ikke har gjort det)\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Last inn dataset fra riktig path\n",
        "dataset = load_from_disk(\"/content/drive/MyDrive/KVP10k_processed_ready/dataset_all_gts\")\n",
        "\n",
        "# Hent splits\n",
        "train_dataset = dataset[\"train\"].select(range(5000))\n",
        "eval_dataset = dataset[\"eval\"].select(range(1000))\n",
        "test_dataset = dataset[\"test\"].select(range(200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEkZt_FZWeuV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def add_entity_pairs_and_labels(example, neg_per_pos: int = 3):\n",
        "    # Hent ut token-labels\n",
        "    labels   = example[\"labels\"]\n",
        "    id2label = {0: \"O\", 1: \"B-KEY\", 2: \"I-KEY\", 3: \"B-VALUE\", 4: \"I-VALUE\"}\n",
        "\n",
        "    # Finn KEY- og VALUE-spans\n",
        "    key_spans, value_spans = [], []\n",
        "    cur_span, cur_type = [], None\n",
        "    for i, lab in enumerate(labels):\n",
        "        if lab == -100:\n",
        "            continue\n",
        "        lbl = id2label[int(lab)]\n",
        "        if lbl.startswith(\"B-\"):\n",
        "            # lagre forrige span\n",
        "            if cur_span:\n",
        "                (key_spans if cur_type==\"KEY\" else value_spans).append(cur_span)\n",
        "            cur_span = [i]\n",
        "            cur_type = lbl.split(\"-\",1)[1]\n",
        "        elif lbl.startswith(\"I-\") and cur_type and lbl.endswith(cur_type):\n",
        "            cur_span.append(i)\n",
        "        else:\n",
        "            if cur_span:\n",
        "                (key_spans if cur_type==\"KEY\" else value_spans).append(cur_span)\n",
        "            cur_span, cur_type = [], None\n",
        "    if cur_span:\n",
        "        (key_spans if cur_type==\"KEY\" else value_spans).append(cur_span)\n",
        "\n",
        "    # Lag positive par\n",
        "    pos_pairs  = [(k, v) for k, v in zip(key_spans, value_spans)]\n",
        "    pos_labels = [1.0] * len(pos_pairs)\n",
        "\n",
        "    # Lag negative par\n",
        "    neg_pairs, neg_labels = [], []\n",
        "    if key_spans and value_spans:\n",
        "        for k in key_spans:\n",
        "            # kandidater som ikke er ekte par\n",
        "            cands = [v for v in value_spans if (k,v) not in pos_pairs]\n",
        "            for v in random.sample(cands, min(len(cands), neg_per_pos)):\n",
        "                neg_pairs.append((k, v))\n",
        "                neg_labels.append(0.0)\n",
        "\n",
        "    # Fallback om ingen par\n",
        "    if not pos_pairs:\n",
        "        pos_pairs, pos_labels = [([0],[1])], [0.0]\n",
        "\n",
        "    # Kombiner og tilordne\n",
        "    example[\"entity_pairs\"] = pos_pairs + neg_pairs\n",
        "    example[\"rel_labels\"]    = pos_labels + neg_labels\n",
        "    return example\n",
        "\n",
        "# Apply to your datasets:\n",
        "train_dataset = train_dataset.map(lambda ex: add_entity_pairs_and_labels(ex, neg_per_pos=3))\n",
        "eval_dataset  = eval_dataset.map(lambda ex: add_entity_pairs_and_labels(ex, neg_per_pos=1))\n",
        "test_dataset  = test_dataset.map(lambda ex: add_entity_pairs_and_labels(ex, neg_per_pos=1))\n",
        "\n",
        "# And then:\n",
        "train_dataset.set_format(\"torch\")\n",
        "eval_dataset.set_format(\"torch\")\n",
        "test_dataset.set_format(\"torch\")\n",
        "\n",
        "\n",
        "# Sjekk at alt fungerer\n",
        "print(\"Train:\", len(train_dataset))\n",
        "print(\"Eval:\", len(eval_dataset))\n",
        "print(\"Test:\", len(test_dataset))\n",
        "print(\"Keys:\", train_dataset[0].keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya332BhmGLt_"
      },
      "outputs": [],
      "source": [
        "train_dataset.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EB3kZmZpTu-m"
      },
      "outputs": [],
      "source": [
        "example = train_dataset[0]\n",
        "for k,v in example.items():\n",
        "    print(k,v.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GTN1cXBYTynu"
      },
      "outputs": [],
      "source": [
        "processor.tokenizer.decode(train_dataset[0][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hhU1sClvWGOS"
      },
      "outputs": [],
      "source": [
        "for id, label in zip(train_dataset[0][\"input_ids\"], train_dataset[0][\"labels\"]):\n",
        "  print(processor.tokenizer.decode([id]), label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85WPa0CnB9oT"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    out = {}\n",
        "    # Stack standard tensors\n",
        "    for k in (\"input_ids\", \"bbox\", \"attention_mask\", \"labels\", \"image\"):\n",
        "        if k in batch[0]:\n",
        "            out[k] = torch.stack([b[k] for b in batch])\n",
        "\n",
        "    # Pad and stack rel_labels\n",
        "    max_rel = max(len(b[\"rel_labels\"]) for b in batch)\n",
        "    rels = []\n",
        "    for b in batch:\n",
        "        lab = b[\"rel_labels\"]\n",
        "        lab = lab.tolist() if isinstance(lab, torch.Tensor) else lab\n",
        "        pad = lab + [0.0] * (max_rel - len(lab))\n",
        "        rels.append(torch.tensor(pad, dtype=torch.float))\n",
        "    out[\"rel_labels\"] = torch.stack(rels)\n",
        "\n",
        "    # Collect entity_pairs directly\n",
        "    out[\"entity_pairs\"] = [b[\"entity_pairs\"] for b in batch]\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JeBWEZzCFKj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "eval_loader  = DataLoader(eval_dataset,  batch_size=8, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEVsZw_vDaHL"
      },
      "outputs": [],
      "source": [
        "label_list = [\"O\", \"B-KEY\", \"I-KEY\", \"B-VALUE\", \"I-VALUE\"]\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrotUlpib9Mh"
      },
      "source": [
        "#Oppsett av Utvidet Layoutmvl3 model med et relasjons lag\n",
        "Vi setter opp en base model som med et binært relasjonslag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiG8y0XzqShC"
      },
      "source": [
        "##Setter opp metode for rekne ut metrikker for treningen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nAjhdhwa1fh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "\n",
        "    # === Token classification metrics (BIO tagging) – unchanged\n",
        "    token_preds = predictions[\"token_logits\"]\n",
        "    token_labels = labels[\"labels\"]\n",
        "\n",
        "    token_preds = np.argmax(token_preds, axis=2)\n",
        "    true_preds = [\n",
        "        [id2label[p] for (p, l) in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(token_preds, token_labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(token_preds, token_labels)\n",
        "    ]\n",
        "\n",
        "    bio_result = metric.compute(predictions=true_preds, references=true_labels)\n",
        "\n",
        "    # === Relation classification metrics (per‐pair binary) ===\n",
        "    rel_logits = predictions[\"rel_logits\"]    # shape (batch_size, max_pairs)\n",
        "    rel_labels = labels[\"rel_labels\"]         # same shape\n",
        "\n",
        "    if rel_logits is not None and rel_labels is not None:\n",
        "        # sigmoid → threshold → flatten\n",
        "        rel_probs      = 1 / (1 + np.exp(-rel_logits))\n",
        "        rel_preds_bin  = (rel_probs >= 0.5).astype(int).ravel()\n",
        "        rel_labels_flat= np.array(rel_labels, dtype=int).ravel()\n",
        "\n",
        "        rel_acc       = accuracy_score(rel_labels_flat, rel_preds_bin)\n",
        "        rel_f1        = f1_score(rel_labels_flat, rel_preds_bin, average=\"macro\")\n",
        "        rel_precision = precision_score(rel_labels_flat, rel_preds_bin, average=\"macro\")\n",
        "        rel_recall    = recall_score(rel_labels_flat, rel_preds_bin, average=\"macro\")\n",
        "    else:\n",
        "        rel_acc = rel_f1 = rel_precision = rel_recall = 0.0\n",
        "\n",
        "    return {\n",
        "        # BIO tagging\n",
        "        \"precision\": bio_result[\"overall_precision\"],\n",
        "        \"recall\":    bio_result[\"overall_recall\"],\n",
        "        \"f1\":        bio_result[\"overall_f1\"],\n",
        "        \"accuracy\":  bio_result[\"overall_accuracy\"],\n",
        "\n",
        "        # Relation prediction\n",
        "        \"rel_acc\":       rel_acc,\n",
        "        \"rel_f1\":        rel_f1,\n",
        "        \"rel_precision\": rel_precision,\n",
        "        \"rel_recall\":    rel_recall\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5wRGzMiqZAT"
      },
      "source": [
        "##Definerer modellen når"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8dC_UZifoz1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import LayoutLMv3Model\n",
        "\n",
        "\n",
        "class RelationExtractionHead(nn.Module):\n",
        "    def __init__(self, hidden_size, num_relations):\n",
        "        super().__init__()\n",
        "        self.head_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.tail_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.bilinear = nn.Bilinear(hidden_size, hidden_size, num_relations)\n",
        "\n",
        "    def forward(self, h_i, h_j):\n",
        "        head = self.head_proj(h_i)\n",
        "        tail = self.tail_proj(h_j)\n",
        "        logits = self.bilinear(head, tail)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DzA5KFAdeA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import LayoutLMv3Model\n",
        "\n",
        "class LayoutWithRelationModelV3(nn.Module):\n",
        "    \"\"\"\n",
        "    LayoutLMv3-basert modell som bruker token-probabiliteter\n",
        "    (token_probs) sammen med span-hidden-states for relasjonsklassifisering.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = \"microsoft/layoutlmv3-base\",\n",
        "        hidden_size: int = 768,\n",
        "        num_labels: int = 5  # antall BIO-klasser\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # Grunnmodell\n",
        "        self.layout = LayoutLMv3Model.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # Token-klassifisering (BIO)\n",
        "        self.token_classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        # Relasjonslag: h_i, h_j, h_mul, h_diff, h_dot, p_i, p_j\n",
        "        rel_in = 4 * hidden_size + 1 + 2 * num_labels\n",
        "        self.rel_fc = nn.Sequential(\n",
        "            nn.Linear(rel_in, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids,\n",
        "        bbox,\n",
        "        pixel_values=None,\n",
        "        attention_mask=None,\n",
        "        labels=None,\n",
        "        entity_pairs=None,\n",
        "        rel_labels=None\n",
        "    ):\n",
        "        # 1) LayoutLMv3 encoding\n",
        "        outputs = self.layout(\n",
        "            input_ids=input_ids,\n",
        "            bbox=bbox,\n",
        "            pixel_values=pixel_values,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "        hidden_states = self.dropout(outputs.last_hidden_state)  # (B, seq_len, H)\n",
        "\n",
        "        # 2) Token-klassifisering\n",
        "        token_logits = self.token_classifier(hidden_states)    # (B, seq_len, L)\n",
        "        token_loss = None\n",
        "        if labels is not None:\n",
        "            token_loss = nn.CrossEntropyLoss()(  # BIO-tap\n",
        "                token_logits.view(-1, token_logits.size(-1)),\n",
        "                labels.view(-1)\n",
        "            )\n",
        "        # Probabiliteter for hver token og klasse\n",
        "        token_probs = F.softmax(token_logits, dim=-1)\n",
        "        token_preds = token_logits.argmax(dim=-1)\n",
        "\n",
        "        # 3) Relasjonsklassifisering\n",
        "        rel_logits, rel_preds, rel_loss = None, None, None\n",
        "        if entity_pairs is not None:\n",
        "            batch_scores = []\n",
        "            for b_idx, pairs in enumerate(entity_pairs):\n",
        "                h_b     = hidden_states[b_idx]  # (seq_len, H)\n",
        "                probs_b = token_probs[b_idx]    # (seq_len, L)\n",
        "                scores = []\n",
        "                for hi_idxs, ti_idxs in pairs:\n",
        "                    # Mean hidden for spans\n",
        "                    h_i = h_b[hi_idxs].mean(dim=0)\n",
        "                    h_j = h_b[ti_idxs].mean(dim=0)\n",
        "                    # Span-interaksjoner\n",
        "                    h_mul  = h_i * h_j\n",
        "                    h_diff = h_i - h_j\n",
        "                    h_dot  = torch.sum(h_i * h_j, dim=0, keepdim=True)\n",
        "                    # Mean token-prob for spans\n",
        "                    p_i = probs_b[hi_idxs].mean(dim=0)\n",
        "                    p_j = probs_b[ti_idxs].mean(dim=0)\n",
        "                    # Samle feature-vektor\n",
        "                    feats = torch.cat([h_i, h_j, h_mul, h_diff, h_dot, p_i, p_j], dim=0)\n",
        "                    scores.append(self.rel_fc(feats).squeeze())\n",
        "                batch_scores.append(torch.stack(scores))\n",
        "\n",
        "            # Pad for lik lengde\n",
        "            max_pairs = max(s.size(0) for s in batch_scores)\n",
        "            padded = []\n",
        "            for s in batch_scores:\n",
        "                if s.size(0) < max_pairs:\n",
        "                    pad = s.new_zeros(max_pairs - s.size(0))\n",
        "                    s = torch.cat([s, pad], dim=0)\n",
        "                padded.append(s)\n",
        "            rel_logits = torch.stack(padded)            # (B, max_pairs)\n",
        "            rel_preds = (torch.sigmoid(rel_logits) >= 0.5).long()\n",
        "            if rel_labels is not None:\n",
        "                rel_loss = nn.BCEWithLogitsLoss()(rel_logits, rel_labels.float())\n",
        "\n",
        "        # 4) Kombiner tap\n",
        "        loss = None\n",
        "        if token_loss is not None and rel_loss is not None:\n",
        "            loss = token_loss + 0.5 * rel_loss\n",
        "        else:\n",
        "            loss = token_loss if token_loss is not None else rel_loss\n",
        "\n",
        "        return {\n",
        "            \"loss\":          loss,\n",
        "            \"token_logits\":  token_logits,\n",
        "            \"token_preds\":   token_preds,\n",
        "            \"rel_logits\":    rel_logits,\n",
        "            \"rel_preds\":     rel_preds,\n",
        "            \"hidden_states\": hidden_states\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4gp7_LQdmII"
      },
      "source": [
        "#Trainer oppsett\n",
        "Inneholder:\n",
        "  - Modellen (LayoutLMv3ForTokenClassification)\n",
        "  - Args (hyperparametre som: epochs, batch_size, lr, lr_scheduler,    regularisering, eval_steps, metrics)\n",
        "  - Datasetsplit (train, eval)\n",
        "  - Tokenizer (from processor)\n",
        "  - Collator (litt usikker på denne)\n",
        "  - Metrikker for modellen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JFnZ7a1qBZW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# === Freeze backbone if token-only training is needed (optional)\n",
        "def freeze_backbone(model):\n",
        "    for param in model.layout.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# === Full training loop\n",
        "\n",
        "def train_full_model(model, train_loader, eval_loader, optimizer, epochs=2, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
        "    model.to(device)\n",
        "    model.device = device  # <--- Ensure the model has a .device attribute\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch} Train\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                \"bbox\": batch[\"bbox\"].to(device),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "                \"labels\": batch[\"labels\"].to(device),\n",
        "                \"image\": batch.get(\"image\", None).to(device) if \"image\" in batch and batch[\"image\"] is not None else None,\n",
        "                \"entity_pairs\": batch.get(\"entity_pairs\"),\n",
        "                \"rel_labels\": batch.get(\"rel_labels\").to(device) if batch.get(\"rel_labels\") is not None else None\n",
        "            }\n",
        "            output = model(**inputs)\n",
        "            loss = output[\"loss\"]\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch} - Avg Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # === Evaluation\n",
        "        model.eval()\n",
        "        all_token_preds, all_token_labels = [], []\n",
        "        all_rel_preds, all_rel_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(eval_loader, desc=f\"Epoch {epoch} Eval\"):\n",
        "                inputs = {\n",
        "                    \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                    \"bbox\": batch[\"bbox\"].to(device),\n",
        "                    \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "                    \"labels\": batch[\"labels\"].to(device),\n",
        "                    \"image\": batch.get(\"image\", None).to(device) if \"image\" in batch and batch[\"image\"] is not None else None,\n",
        "                    \"entity_pairs\": batch.get(\"entity_pairs\"),\n",
        "                    \"rel_labels\": batch.get(\"rel_labels\").to(device) if batch.get(\"rel_labels\") is not None else None\n",
        "                }\n",
        "                output = model(**inputs)\n",
        "\n",
        "                # === Token metrics\n",
        "                logits = output[\"token_logits\"].argmax(-1).cpu()\n",
        "                label_ids = inputs[\"labels\"].cpu()\n",
        "                for p_seq, l_seq in zip(logits, label_ids):\n",
        "                    for p, l in zip(p_seq.tolist(), l_seq.tolist()):\n",
        "                        if l != -100:\n",
        "                            all_token_preds.append(p)\n",
        "                            all_token_labels.append(l)\n",
        "\n",
        "                # === Relation metrics (pairwise binary predictions)\n",
        "                if output[\"rel_logits\"] is not None and inputs[\"rel_labels\"] is not None:\n",
        "                    rel_logits = output[\"rel_logits\"]\n",
        "                    rel_labels = inputs[\"rel_labels\"]\n",
        "\n",
        "                    for pred_vec, label_vec in zip(torch.sigmoid(rel_logits), rel_labels):\n",
        "                        pred_bin = (pred_vec >= 0.5).long()\n",
        "                        all_rel_preds.extend(pred_bin.cpu().tolist())\n",
        "                        all_rel_labels.extend(label_vec.long().cpu().tolist())\n",
        "\n",
        "        # === Print token classification report\n",
        "        print(\"\\nToken Classification Report:\")\n",
        "        print(classification_report(all_token_labels, all_token_preds, target_names=list(id2label.values())))\n",
        "\n",
        "        # === Print relation classification report (if available)\n",
        "        if all_rel_preds:\n",
        "            print(\"\\nRelation Classification Report:\")\n",
        "            print(classification_report(all_rel_labels, all_rel_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg8bMcM5dmYW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model = LayoutWithRelationModel(\n",
        "    model_name=\"microsoft/layoutlmv3-base\",\n",
        "    hidden_size=768,\n",
        "    num_labels=len(id2label)\n",
        ").to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "train_full_model(model, train_loader, eval_loader, optimizer, epochs=1, device=device) # TODO endre tilbake til 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n5t8TB-eyWu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "output_dir = \"/content/drive/MyDrive/KVP10k-layoutlmv3-v6\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Lagre modell\n",
        "torch.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
        "processor.save_pretrained(output_dir)\n",
        "\n",
        "# Lagre prosessor\n",
        "processor.save_pretrained(output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJinDzWcwpUL"
      },
      "source": [
        "#INFERENCE\n",
        "Laster inn beste fine-tuned modell og dens tilhørende processor fra Drive, samt tilleggsinformasjon som kreves av processoren.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gftv6oBQ8Rjl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/KVP10k-layoutlmv3-v6\"\n",
        "hidden_size = 768\n",
        "num_labels = len(id2label)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_path, local_files_only=True)\n",
        "\n",
        "model = LayoutWithRelationModel(\n",
        "    model_name=\"microsoft/layoutlmv3-base\",\n",
        "    hidden_size=hidden_size,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "model.load_state_dict(torch.load(f\"{model_path}/pytorch_model.bin\", map_location=\"cpu\"))\n",
        "model.to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzzMQnpi0xUz"
      },
      "source": [
        "#Kode prediksjon og visualisering av dette\n",
        "###*Tokenisering og input-prosessering med Layout sin Processor ved inference*\n",
        "Processor brukes her til å gjøre om tekst, bboxes, og bilde til format modell krever. Dette inkl:\n",
        "- Tokenisering\n",
        "- Normalisering av bboxes tilhørende hvert token\n",
        "- Skalering av bilde\n",
        "- Generering av input-tensorer\n",
        "\n",
        "NB: Denne prosessen gjøres allerede i Data_Processor notebooken som ferdigstilte datasettet for **denne** notebooken. Selve prosessen er dermed nesten indentisk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3DDG0gwdC0Y"
      },
      "outputs": [],
      "source": [
        "#Nødvendig for å plassere boksene på originalt-format på bilde-dokumentet\n",
        "def unnormalize_box(bbox, width, height):\n",
        "    return [\n",
        "        width * (bbox[0] / 1000),\n",
        "        height * (bbox[1] / 1000),\n",
        "        width * (bbox[2] / 1000),\n",
        "        height * (bbox[3] / 1000),\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSekHOh_dR71"
      },
      "source": [
        "#Velg vilkårlig dokument fra datasettet og prediker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l5scTZgoZx6"
      },
      "outputs": [],
      "source": [
        "# === Velg dokument\n",
        "#document_selected = \"aaf643426f0250efd10de3d9df63b407292f3fcc2aa335e399c37aca32443ea1\"\n",
        "document_selected = \"aaed61e79aa3edbae844f5775789ebb6aa1a94a23d9cb3468d2cfc974af304e5\"\n",
        "# document_selected = \"aa35720ba3611f946c372cc99d8cd1d78e81265b8ceb51dcdb4672d196944c2b\"\n",
        "# document_selected = \"faa5d71172e2e9959b41a5aec4fd2ab700534d1b2729484d2d5f26472cd56cfa\"\n",
        "# document_selected = \"ffe462e43b9dff12e78ea8fb69332abfb789da171a8597f5bb961853e06e6fa2\"\n",
        "# document_selected = \"feb2c4b21388318c7a51cc0aaf0e7c673a07f5204a40549a281bef065bb77925\"\n",
        "# document_selected = \"feaf84d435bd46100db82de51f5a989ff4d39fdcdb040a7044720b943e34b7d7\"\n",
        "# document_selected = \"df6b0a4cf1908bb95be874e4efa59411c685095d7bb596879961563503b5c239\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raGVbLf4mnTU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_token_head(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            bbox = batch[\"bbox\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            output = model(\n",
        "                input_ids=input_ids,\n",
        "                bbox=bbox,\n",
        "                attention_mask=attention_mask,\n",
        "                image=batch.get(\"image\")\n",
        "            )\n",
        "            token_logits = output[\"token_logits\"]\n",
        "            preds = token_logits.argmax(-1)\n",
        "\n",
        "            for p_seq, l_seq in zip(preds, labels):\n",
        "                for p, l in zip(p_seq.cpu().tolist(), l_seq.cpu().tolist()):\n",
        "                    if l != -100:\n",
        "                        all_preds.append(p)\n",
        "                        all_labels.append(l)\n",
        "\n",
        "    print(classification_report(all_labels, all_preds, target_names=list(id2label.values())))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYy05IO9ofy4"
      },
      "outputs": [],
      "source": [
        "evaluate_token_head(model, eval_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvxo2tvfdDWA"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "\n",
        "def predict_tokens(doc_id, show_gt=True):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    base_path = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/test\"\n",
        "    image_path = f\"{base_path}/images/{doc_id}.png\"\n",
        "    ocr_path = f\"{base_path}/ocrs/{doc_id}.json\"\n",
        "    gt_path = f\"{base_path}/gts/{doc_id}.json\"\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ocr_data = json.load(f)\n",
        "    with open(gt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        gt_data = json.load(f)\n",
        "\n",
        "    page = ocr_data[\"pages\"][0]\n",
        "    words = [w[\"text\"] for w in page[\"words\"]]\n",
        "    raw_boxes = [w[\"bbox\"] for w in page[\"words\"]]\n",
        "    width, height = page[\"width\"], page[\"height\"]\n",
        "    norm_boxes = [normalize_bbox(b, width, height) for b in raw_boxes]\n",
        "\n",
        "    string_labels = iob_from_kvps(words, raw_boxes, gt_data[\"kvps_list\"])\n",
        "    word_labels = [label_map.get(lbl, 0) for lbl in string_labels]\n",
        "\n",
        "    encoding = processor(\n",
        "        image,\n",
        "        words,\n",
        "        boxes=norm_boxes,\n",
        "        word_labels=word_labels,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    word_ids = encoding.word_ids()\n",
        "    labels = [-100] * len(word_ids)\n",
        "    for idx, word_idx in enumerate(word_ids):\n",
        "        if word_idx is None:\n",
        "            continue\n",
        "        label_str = string_labels[word_idx]\n",
        "        labels[idx] = label_map[label_str]\n",
        "    encoding[\"labels\"] = torch.tensor([labels])\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in encoding.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            bbox=inputs[\"bbox\"],\n",
        "            image=inputs[\"pixel_values\"],\n",
        "            attention_mask=inputs[\"attention_mask\"]\n",
        "        )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].squeeze().tolist()\n",
        "    predictions = outputs[\"token_logits\"].argmax(-1).squeeze().tolist()\n",
        "    bboxes = inputs[\"bbox\"].squeeze().tolist()\n",
        "    unnorm_boxes = [unnormalize_box(b, width, height) for b in bboxes]\n",
        "    tokens = [processor.tokenizer.decode([tid]) for tid in input_ids]\n",
        "\n",
        "    filtered = [\n",
        "        (token, id2label.get(pred, \"O\"), box)\n",
        "        for token, pred, box in zip(tokens, predictions, unnorm_boxes)\n",
        "        if token not in [\"[PAD]\", \"[CLS]\", \"[SEP]\"]\n",
        "    ]\n",
        "\n",
        "    print(\"Unike labels i output:\", set(p[1] for p in filtered))\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "    def iob_to_label(label):\n",
        "        return label[2:].lower() if label.startswith((\"B-\", \"I-\")) else \"other\"\n",
        "\n",
        "    label2color = {\n",
        "        \"key\": \"blue\",\n",
        "        \"value\": \"green\",\n",
        "        \"other\": \"gray\"\n",
        "    }\n",
        "\n",
        "    for token, pred_label, box in filtered:\n",
        "        if pred_label == \"O\":\n",
        "            continue\n",
        "        label_type = iob_to_label(pred_label)\n",
        "        draw.rectangle(box, outline=label2color.get(label_type, \"red\"), width=2)\n",
        "        draw.text((box[0] + 5, box[1] - 10), label_type, fill=label2color.get(label_type, \"red\"), font=font)\n",
        "\n",
        "    print(\"Modellens prediksjoner:\")\n",
        "    display(image)\n",
        "\n",
        "    if show_gt:\n",
        "        gt_img = Image.open(image_path).convert(\"RGB\")\n",
        "        draw_gt = ImageDraw.Draw(gt_img)\n",
        "        for word, box, label_id in zip(words, raw_boxes, string_labels):\n",
        "            if label_id == \"O\":\n",
        "                continue\n",
        "            label_type = iob_to_label(label_id)\n",
        "            draw_gt.rectangle(box, outline=label2color.get(label_type, \"gray\"), width=2)\n",
        "            draw_gt.text((box[0] + 5, box[1] - 10), label_type, fill=label2color.get(label_type, \"gray\"), font=font)\n",
        "\n",
        "        print(\"Ground Truth:\")\n",
        "        display(gt_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QS92Sq_JwuBV"
      },
      "outputs": [],
      "source": [
        "predict_tokens(document_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPD79RD5dNGu"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "import json, torch, math\n",
        "\n",
        "def predict_relations(doc_id: str, threshold: float = 0.5):\n",
        "    # ─── helper to extract BIO spans ──────────────────────────────\n",
        "    def extract_spans(labels, kind):\n",
        "        spans, cur = [], []\n",
        "        for idx, lab in enumerate(labels):\n",
        "            if lab == f\"B-{kind}\":\n",
        "                if cur: spans.append(cur)\n",
        "                cur = [idx]\n",
        "            elif lab == f\"I-{kind}\" and cur:\n",
        "                cur.append(idx)\n",
        "            else:\n",
        "                if cur: spans.append(cur)\n",
        "                cur = []\n",
        "        if cur: spans.append(cur)\n",
        "        return spans\n",
        "\n",
        "    # ─── load image & OCR ─────────────────────────────────────────\n",
        "    base      = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/test\"\n",
        "    img_path  = f\"{base}/images/{doc_id}.png\"\n",
        "    ocr_path  = f\"{base}/ocrs/{doc_id}.json\"\n",
        "    image     = Image.open(img_path).convert(\"RGB\")\n",
        "    with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ocr = json.load(f)\n",
        "\n",
        "    page       = ocr[\"pages\"][0]\n",
        "    words      = [w[\"text\"] for w in page[\"words\"]]\n",
        "    raw_boxes  = [w[\"bbox\"] for w in page[\"words\"]]\n",
        "    W, H       = page[\"width\"], page[\"height\"]\n",
        "    norm_boxes = [normalize_bbox(b, W, H) for b in raw_boxes]\n",
        "\n",
        "    # ─── run processor & model (batch size = 1) ───────────────────\n",
        "    enc = processor(\n",
        "        image, words, boxes=norm_boxes,\n",
        "        return_tensors=\"pt\", truncation=True, padding=\"max_length\"\n",
        "    )\n",
        "    token_boxes = enc[\"bbox\"][0].cpu().tolist()\n",
        "    for k in (\"input_ids\",\"bbox\",\"pixel_values\",\"attention_mask\"):\n",
        "        enc[k] = enc[k].to(device)\n",
        "\n",
        "    # ─── 1) hent ut token-labels og spans ─────────────────────────\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out_tokens = model(\n",
        "            input_ids     = enc[\"input_ids\"],\n",
        "            bbox          = enc[\"bbox\"],\n",
        "            image  = enc[\"pixel_values\"],\n",
        "            attention_mask= enc[\"attention_mask\"]\n",
        "        )\n",
        "    # decode BIO-prediksjoner\n",
        "    pred_ids     = out_tokens[\"token_logits\"][0].argmax(-1).tolist()\n",
        "    labels_pred  = [id2label.get(i, \"O\") for i in pred_ids]\n",
        "    key_spans    = extract_spans(labels_pred, \"KEY\")\n",
        "    value_spans  = extract_spans(labels_pred, \"VALUE\")\n",
        "\n",
        "    # ─── 2) lag entity_pairs-listen slik modellen forventer ───────\n",
        "    pairs = [(k_span, v_span) for k_span in key_spans for v_span in value_spans]\n",
        "\n",
        "    # ─── 3) kjør forward på nytt med entity_pairs for relasjons‐logits ─\n",
        "    with torch.no_grad():\n",
        "        out = model(\n",
        "            input_ids     = enc[\"input_ids\"],\n",
        "            bbox          = enc[\"bbox\"],\n",
        "            image  = enc[\"pixel_values\"],\n",
        "            attention_mask= enc[\"attention_mask\"],\n",
        "            entity_pairs  = [pairs]  # batch av lengde 1\n",
        "        )\n",
        "\n",
        "    rel_logits = out[\"rel_logits\"][0]  # tensor of shape (num_pairs,)\n",
        "    relations  = []\n",
        "    for idx, (k_span, v_span) in enumerate(pairs):\n",
        "        prob = torch.sigmoid(rel_logits[idx]).item()\n",
        "        if prob >= threshold:\n",
        "            relations.append((k_span, v_span, prob))\n",
        "\n",
        "    # ─── 4) tegne resultatene ──────────────────────────────────────\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "    arrow_len   = 15\n",
        "    arrow_angle = math.radians(25)\n",
        "\n",
        "    if not relations:\n",
        "        draw.text((10,10), \"Ingen relasjoner funnet\", fill=\"orange\", font=font)\n",
        "    else:\n",
        "        for k_span, v_span, prob in relations:\n",
        "            # bokser\n",
        "            for i in k_span:\n",
        "                draw.rectangle(unnormalize_box(token_boxes[i], W, H),\n",
        "                               outline=\"blue\", width=2)\n",
        "            for i in v_span:\n",
        "                draw.rectangle(unnormalize_box(token_boxes[i], W, H),\n",
        "                               outline=\"green\", width=2)\n",
        "\n",
        "            # pil fra key til value (samme som før)\n",
        "            kxs = [(b[0]+b[2])/2 for idx in k_span for b in [token_boxes[idx]]]\n",
        "            kys = [(b[1]+b[3])/2 for idx in k_span for b in [token_boxes[idx]]]\n",
        "            vxs = [(b[0]+b[2])/2 for idx in v_span for b in [token_boxes[idx]]]\n",
        "            vys = [(b[1]+b[3])/2 for idx in v_span for b in [token_boxes[idx]]]\n",
        "            kc  = ((sum(kxs)/len(kxs))*W/1000, (sum(kys)/len(kys))*H/1000)\n",
        "            vc  = ((sum(vxs)/len(vxs))*W/1000, (sum(vys)/len(vys))*H/1000)\n",
        "\n",
        "            dx, dy = vc[0]-kc[0], vc[1]-kc[1]\n",
        "            dist    = math.hypot(dx, dy)\n",
        "            if dist > arrow_len:\n",
        "                ux, uy    = dx/dist, dy/dist\n",
        "                tail      = (kc[0], kc[1])\n",
        "                head_base = (vc[0]-ux*arrow_len, vc[1]-uy*arrow_len)\n",
        "                draw.line([tail, head_base], fill=\"red\", width=2)\n",
        "            else:\n",
        "                head_base = kc\n",
        "\n",
        "            ux, uy = (vc[0]-head_base[0])/arrow_len, (vc[1]-head_base[1])/arrow_len\n",
        "            left_x  = vc[0] - arrow_len*(ux*math.cos(arrow_angle) + uy*math.sin(arrow_angle))\n",
        "            left_y  = vc[1] - arrow_len*(uy*math.cos(arrow_angle) - ux*math.sin(arrow_angle))\n",
        "            right_x = vc[0] - arrow_len*(ux*math.cos(arrow_angle) - uy*math.sin(arrow_angle))\n",
        "            right_y = vc[1] - arrow_len*(uy*math.cos(arrow_angle) + ux*math.sin(arrow_angle))\n",
        "            draw.polygon([vc, (left_x,left_y), (right_x,right_y)], fill=\"red\")\n",
        "\n",
        "            draw.text((vc[0]+3, vc[1]-10), f\"{prob:.2f}\",\n",
        "                      fill=\"red\", font=font)\n",
        "\n",
        "    display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmPFBUPRcUJi"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "import json, torch, math\n",
        "\n",
        "def predict_relations_per_key(doc_id: str, threshold: float = 0.5):\n",
        "    # ─── helper for å hente ut BIO-spans, kun der mask==1 ─────────────\n",
        "    def extract_spans(labels, mask, kind):\n",
        "        spans, cur = [], []\n",
        "        for idx, (lab, m) in enumerate(zip(labels, mask)):\n",
        "            if m == 0:             # pad‐token ⇒ avslutt span\n",
        "                if cur:\n",
        "                    spans.append(cur)\n",
        "                    cur = []\n",
        "                continue\n",
        "            if lab == f\"B-{kind}\":\n",
        "                if cur:\n",
        "                    spans.append(cur)\n",
        "                cur = [idx]\n",
        "            elif lab == f\"I-{kind}\" and cur:\n",
        "                cur.append(idx)\n",
        "            else:\n",
        "                if cur:\n",
        "                    spans.append(cur)\n",
        "                    cur = []\n",
        "        if cur:\n",
        "            spans.append(cur)\n",
        "        return spans\n",
        "\n",
        "    # ─── 1) Load image + OCR ────────────────────────────────────────\n",
        "    base      = \"/content/drive/MyDrive/KVP10k-dataset/kvp10k/test\"\n",
        "    img_path  = f\"{base}/images/{doc_id}.png\"\n",
        "    ocr_path  = f\"{base}/ocrs/{doc_id}.json\"\n",
        "    image     = Image.open(img_path).convert(\"RGB\")\n",
        "    with open(ocr_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        ocr = json.load(f)\n",
        "\n",
        "    page       = ocr[\"pages\"][0]\n",
        "    words      = [w[\"text\"]  for w in page[\"words\"]]\n",
        "    raw_boxes  = [w[\"bbox\"]  for w in page[\"words\"]]\n",
        "    W, H       = page[\"width\"], page[\"height\"]\n",
        "    norm_boxes = [normalize_bbox(b, W, H) for b in raw_boxes]\n",
        "\n",
        "    # ─── 2) Token‐klassifisering for spans ───────────────────────────\n",
        "    enc = processor(\n",
        "        image, words, boxes=norm_boxes,\n",
        "        return_tensors=\"pt\", truncation=True, padding=\"max_length\"\n",
        "    )\n",
        "    token_boxes = enc[\"bbox\"][0].cpu().tolist()\n",
        "    for k in (\"input_ids\",\"bbox\",\"pixel_values\",\"attention_mask\"):\n",
        "        enc[k] = enc[k].to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out_tokens = model(\n",
        "            input_ids     = enc[\"input_ids\"],\n",
        "            bbox          = enc[\"bbox\"],\n",
        "            image  = enc[\"pixel_values\"],\n",
        "            attention_mask= enc[\"attention_mask\"]\n",
        "        )\n",
        "\n",
        "    # hent prediksjoner + mask\n",
        "    pred_ids    = out_tokens[\"token_logits\"][0].argmax(-1).tolist()\n",
        "    mask        = enc[\"attention_mask\"][0].cpu().tolist()\n",
        "    labels_pred = [id2label.get(i, \"O\") for i in pred_ids]\n",
        "\n",
        "    # finn spans, kun der mask==1\n",
        "    key_spans   = extract_spans(labels_pred, mask, \"KEY\")\n",
        "    value_spans = extract_spans(labels_pred, mask, \"VALUE\")\n",
        "\n",
        "    # ─── 3) Bygg (key,value)-par og hent rel_logits ─────────────────\n",
        "    pairs = [(k, v) for k in key_spans for v in value_spans]\n",
        "    with torch.no_grad():\n",
        "        out = model(\n",
        "            input_ids     = enc[\"input_ids\"],\n",
        "            bbox          = enc[\"bbox\"],\n",
        "            image  = enc[\"pixel_values\"],\n",
        "            attention_mask= enc[\"attention_mask\"],\n",
        "            entity_pairs  = [pairs],\n",
        "        )\n",
        "    rel_logits = out[\"rel_logits\"][0]  # (len(pairs),)\n",
        "\n",
        "    # ─── 4) Velg beste VALUE per KEY (over threshold) ───────────────\n",
        "    best_for_key = {}\n",
        "    for idx, (k_span, v_span) in enumerate(pairs):\n",
        "        prob = torch.sigmoid(rel_logits[idx]).item()\n",
        "        key_t = tuple(k_span)\n",
        "        if key_t not in best_for_key or prob > best_for_key[key_t][2]:\n",
        "            best_for_key[key_t] = (k_span, v_span, prob)\n",
        "\n",
        "    relations = [\n",
        "        (k, v, p) for (k, v, p) in best_for_key.values()\n",
        "        if p >= threshold\n",
        "    ]\n",
        "\n",
        "    # ─── 5) Tegn ALLE spans + pil per KEY→beste VALUE ──────────────\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "    arrow_len   = 15\n",
        "    arrow_angle = math.radians(25)\n",
        "\n",
        "    # 5a) alle KEY i blått\n",
        "    for k_span in key_spans:\n",
        "        for i in k_span:\n",
        "            draw.rectangle(\n",
        "                unnormalize_box(token_boxes[i], W, H),\n",
        "                outline=\"blue\", width=2\n",
        "            )\n",
        "\n",
        "    # 5b) alle VALUE i grønt\n",
        "    for v_span in value_spans:\n",
        "        for i in v_span:\n",
        "            draw.rectangle(\n",
        "                unnormalize_box(token_boxes[i], W, H),\n",
        "                outline=\"green\", width=2\n",
        "            )\n",
        "\n",
        "    # 5c) én pil per nøkkel→ value\n",
        "    if not relations:\n",
        "        draw.text((10,10), \"Ingen relasjoner funnet\", fill=\"orange\", font=font)\n",
        "    else:\n",
        "        for k_span, v_span, prob in relations:\n",
        "            # finn senterpunkt\n",
        "            kxs = [(b[0]+b[2])/2 for idx in k_span for b in [token_boxes[idx]]]\n",
        "            kys = [(b[1]+b[3])/2 for idx in k_span for b in [token_boxes[idx]]]\n",
        "            vxs = [(b[0]+b[2])/2 for idx in v_span for b in [token_boxes[idx]]]\n",
        "            vys = [(b[1]+b[3])/2 for idx in v_span for b in [token_boxes[idx]]]\n",
        "            kc  = ((sum(kxs)/len(kxs))*W/1000, (sum(kys)/len(kys))*H/1000)\n",
        "            vc  = ((sum(vxs)/len(vxs))*W/1000, (sum(vys)/len(vys))*H/1000)\n",
        "\n",
        "            dx, dy = vc[0]-kc[0], vc[1]-kc[1]\n",
        "            dist    = math.hypot(dx, dy)\n",
        "            if dist > arrow_len:\n",
        "                ux, uy    = dx/dist, dy/dist\n",
        "                tail      = (kc[0], kc[1])\n",
        "                head_base = (vc[0]-ux*arrow_len, vc[1]-uy*arrow_len)\n",
        "                draw.line([tail, head_base], fill=\"red\", width=2)\n",
        "            else:\n",
        "                head_base = kc\n",
        "\n",
        "            # pilhode\n",
        "            ux, uy = (vc[0]-head_base[0])/arrow_len, (vc[1]-head_base[1])/arrow_len\n",
        "            left_x  = vc[0] - arrow_len*( ux*math.cos(arrow_angle) + uy*math.sin(arrow_angle))\n",
        "            left_y  = vc[1] - arrow_len*( uy*math.cos(arrow_angle) - ux*math.sin(arrow_angle))\n",
        "            right_x = vc[0] - arrow_len*( ux*math.cos(arrow_angle) - uy*math.sin(arrow_angle))\n",
        "            right_y = vc[1] - arrow_len*( uy*math.cos(arrow_angle) + ux*math.sin(arrow_angle))\n",
        "            draw.polygon([vc, (left_x,left_y), (right_x,right_y)], fill=\"red\")\n",
        "\n",
        "            draw.text((vc[0]+3, vc[1]-10), f\"{prob:.2f}\",\n",
        "                      fill=\"red\", font=font)\n",
        "\n",
        "    display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scERip5ToTsO"
      },
      "outputs": [],
      "source": [
        "predict_relations(document_selected)\n",
        "predict_relations_per_key(document_selected)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}